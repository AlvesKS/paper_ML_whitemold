{
  "hash": "0055d71184eed4c7252927985a760de5",
  "result": {
    "markdown": "---\ntitle: Soil data\n---\n\n## Packages\n\n::: {.callout-warning}\n\n# About R packages\n\nMake sure to have all R packages installed before running the analysis described in this website.\n\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(tidyverse)\nlibrary(cowplot)\nlibrary(patchwork)\nlibrary(daymetr)\nlibrary(raster)\nlibrary(spatstat)\nlibrary(KrigR)\nlibrary(lubridate)\nlibrary(sf)\nlibrary(viridis)\nlibrary(terra)\nlibrary(XPolaris)\nlibrary(MetBrewer)\n```\n:::\n\n\n\n## White mold data\n\nLoading white mold data. We are going to use the field coordinates (latitude and longitude) to extract the data from the rasters of soil variables.\n\n::: {.callout-warning}\n\n# About the Data\n\nIn the research [repository](https://osf.io/v53py/){target=\"_blank\"}, the directories containing the soil, weather, white mold are compressed (`data_era5.zip`,`soil_images.zip`, `data_white-mold.zip`). You should unzip these files in the main directory to be able to reproduce the analysis.\n\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nwm_data = read.csv(\"data_white-mold/WhiteMoldSurveyWrangledData.csv\")\n```\n:::\n\n### Removing missing coordinates\n\nThere are some missing coordinates in the dataset. Here we remove them.\n\n::: {.cell}\n\n```{.r .cell-code}\nwm_data2 = wm_data %>% \n  filter(!is.na(latitude))\n```\n:::\n\n## Soil variables\n\n\n### Locations\n\nSetting up the coordinated of each quadrat we need to download the soil data\n\n::: {.cell}\n\n```{.r .cell-code}\n# exkansas\nny_locations = data.frame(ID = c(\"NY1\",\"NY2\",\"NY3\",\"NY4\",\"NY5\",\"NY6\",\"NY7\",\"NY8\"),\n                          lat  = c(42,  42,  42, 42, 43,   43,   43,   43),\n                          long = c(-77, -78,-79, -80,-77, -78.0,-79.0, -80))\n\nxplot(locations = ny_locations)+\n  geom_point(data = wm_data2 , size = 0.3,\n             aes(longitude,latitude))+\n  coord_map( xlim = c(-81,-75),\n             ylim = c(41.5,44.5))\n```\n\n::: {.cell-output-stderr}\n```\nCoordinate system already present. Adding new coordinate system, which will replace the existing one.\n```\n:::\n\n::: {.cell-output-display}\n![](code_soil_variables_white-mold_files/figure-html/unnamed-chunk-5-1.png){width=672}\n:::\n\n```{.r .cell-code}\n# max(wm_data2$longitude)\n```\n:::\n\n### Download soil data\n\n::: {.cell}\n\n```{.r .cell-code}\nny_images <- ximages(locations = ny_locations,\n                      statistics = c('mean'),\n                      variables = c('ph','om','clay',\"sand\",\"silt\",\"bd\", \"hb\",\"n\",\"alpha\",\"ksat\",\"lambda\",\"theta_r\",\"theta_s\"),\n                      layersdepths = c('0_5'),\n                      localPath = file.path(\"soil_images\"))\n```\n:::\n\nHere we read the metadata of the downloaded data. It containg the informatino regarding the directory of each downloaded file.\n\n\n\n### Merge images\n\n#### Organic matter\n\nWe are going to filter only the lines contain information regarding Organic matter\n\n::: {.cell}\n\n```{.r .cell-code}\nom_df_images = ny_images %>% \n  filter(variables == \"om\")\n```\n:::\n\nAs you can notice in the next figure, the raster objects are downloaded in separate raster of 01 degree size\n\n::: {.cell}\n\n```{.r .cell-code}\n# read all files for organic matter\nom_stack = lapply(om_df_images$local_file, brick)\n\n\npar(mfrow = c(2,4))\n\nfor(i in 1:length(om_stack)){\nplot(om_stack[[i]])\n}\n```\n\n::: {.cell-output-display}\n![](code_soil_variables_white-mold_files/figure-html/unnamed-chunk-9-1.png){width=672}\n:::\n:::\n\nTherefore, we use the function `merge()` to create a single raster object covering the whole study region\n\n::: {.cell}\n\n```{.r .cell-code}\nom_ny_raster =merge(om_stack[[1]],\n                    om_stack[[2]],\n                    om_stack[[3]],\n                    om_stack[[4]],\n                    om_stack[[5]],\n                    om_stack[[6]],\n                    om_stack[[7]],\n                    om_stack[[8]])\n\nplot(exp(om_ny_raster))\n```\n\n::: {.cell-output-display}\n![](code_soil_variables_white-mold_files/figure-html/unnamed-chunk-10-1.png){width=672}\n:::\n:::\n\n### Automatization\n\nInstead of doing the above step for each variable by hand, here we created a function to do all the steps automatically.\n\n::: {.cell}\n\n```{.r .cell-code}\nget_soil_var = function(var, data){\n  data_filtered = data %>% \n  filter(variables == var)\n\nstack_list = lapply(data_filtered$local_file, brick)\n  \n  \n  merged_raster = merge(stack_list[[1]],\n                    stack_list[[2]],\n                    stack_list[[3]],\n                    stack_list[[4]],\n                    stack_list[[5]],\n                    stack_list[[6]],\n                    stack_list[[7]],\n                    stack_list[[8]]\n                    )\n  return(merged_raster)\n}\n\nsoil_vars = c('ph','om','clay',\"sand\",\"silt\",\"bd\", \"hb\",\"n\",\"alpha\",\"ksat\",\"lambda\",\"theta_r\",\"theta_s\")\n\nselected_vars = c('ph','om','clay',\"sand\",\"silt\",\"bd\",\"theta_r\",\"theta_s\")\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nsoil_variables_list = lapply(soil_vars,get_soil_var, data = ny_images)\nnames(soil_variables_list) = soil_vars\n\nsaveRDS(soil_variables_list, \"soil_images/list_soil_variables_raster.rds\")\n```\n:::\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\naggre_var_list = lapply(soil_variables_list, aggregate,fact=30)\n\nsaveRDS(aggre_var_list, \"soil_images/list_soil_variables_raster_aggregated.rds\")\n```\n:::\n\n\n\n### Plot soil maps\n\n#### NY shape file\n\nLoading New York state shape file.\n\n::: {.cell}\n\n```{.r .cell-code}\nny_shape1 = readOGR(\"shape_files/cugir-007865/cugir-007865/cty036.shp\")\n```\n\n::: {.cell-output-stdout}\n```\nOGR data source with driver: ESRI Shapefile \nSource: \"G:\\.shortcut-targets-by-id\\1tp3HzkoBOZ0949rE6UQ-y3_WEWrnsmPw\\WhiteMoldSurvey\\01-Kaique\\01-Repository\\shape_files\\cugir-007865\\cugir-007865\\cty036.shp\", layer: \"cty036\"\nwith 67 features\nIt has 80 fields\n```\n:::\n:::\n\n#### Cropping raster files\n\nWe use the function `lappy()` to crop all variables' rasters using the NY shape file as a mask.\n\n::: {.cell}\n\n```{.r .cell-code}\naggre_var_list2 = lapply(aggre_var_list, mask, ny_shape1)\n```\n:::\n\nThen here we create a function for ploting the soil maps.\n\n::: {.cell}\n\n```{.r .cell-code}\nactual_var_names = c(\"Soil pH in water\", \"Soil organic matter\",\"Clay\",\"Sand\",\"Silt\",\"Bulk density\",\"Residual soil water content\",\"Saturated soil water content\")\nactual_var_symbol = c(\"pH\", \"OM\",\"Clay\",\"Sand\",\"Silt\",\"BD\",\"\\u03B8r\",\"\\u03B8s\")\nactual_var_units = c(\"\", \"(%)\",\"(%)\",\"(%)\",\"(%)\",\"(g/cm³)\",\"(m³/m³)\",\"(m³/m³)\")\n\nplot_gg_raster =  function(X,raster, var){\n  # actual_var_names[X]\n\nif(var[X] == \"om\"){xx=1}else{xx = 0}\n  \nas.data.frame(raster[[var[X]]], xy = T) %>%\n    filter(layer !=\"NaN\", x< -76.8) %>%\n  mutate(layer = case_when(xx ==1~ exp(layer),\n                           xx ==0~ layer)) %>% \n    ggplot(aes())+\n    geom_raster(aes(x, y, fill = layer))+\n    scale_fill_viridis(option =\"B\",guide = guide_colorbar(barwidth = 0.2, barheight =5 ))+\n    geom_polygon(data = ny_shape1,\n                 aes(x=long, y = lat, group = group),\n                 fill= NA,\n                 size =0.2,\n                 alpha = 0.5,\n                 color = \"white\")+\n  # geom_point(data = wm_data2 , size = 0.1,color = \"white\",\n  #            aes(longitude,latitude))+\n    coord_quickmap(xlim = c(-80,-76.8), ylim = c(42,43.35))+\n    theme_map()+\n    labs(title =paste(\"    \",actual_var_names[X]),\n         fill = paste(actual_var_symbol[X],actual_var_units[X]))\n}\n\n# selected_vars\n# aggre_var_list[[1]]\n# plot_gg_raster(1,aggre_var_list2, var = selected_vars[1] )\n```\n:::\n\n#### Combo soil maps\n\nHere we plot all maps into a single combo fiure\n\n::: {.cell}\n\n```{.r .cell-code}\ndo.call(patchwork::wrap_plots, lapply(X =1:length(selected_vars) , FUN =plot_gg_raster, raster = aggre_var_list2, var = selected_vars))+\n  plot_layout(ncol = 2)+\n  plot_annotation(tag_levels = \"A\")&\n  theme(legend.position = \"right\",\n        legend.text = element_text(size = 5),\n        legend.title = element_text(size = 5),\n        plot.title =  element_text(size = 7, face = \"bold\"))\n```\n\n::: {.cell-output-stderr}\n```\nRegions defined for each Polygons\nRegions defined for each Polygons\nRegions defined for each Polygons\nRegions defined for each Polygons\nRegions defined for each Polygons\nRegions defined for each Polygons\nRegions defined for each Polygons\nRegions defined for each Polygons\n```\n:::\n\n::: {.cell-output-display}\n![](code_soil_variables_white-mold_files/figure-html/unnamed-chunk-20-1.png){width=672}\n:::\n\n```{.r .cell-code}\nggsave(\"figs/maps/soil_maps.png\", dpi = 900, height = 7, width = 7, bg = \"white\")\n```\n:::\n\n## Extract variables to location\n\n::: {.cell}\n\n```{.r .cell-code}\nwm_data2_uni = wm_data2 %>% \n  group_by(subject) %>% \n  slice(1L)\n```\n:::\n\nSelecting coordinate columns from the white mold data set\n\n::: {.cell}\n\n```{.r .cell-code}\ncoords<-data.frame(lon=wm_data2_uni$longitude, lat=wm_data2_uni$latitude)\ncoordinates(coords)<-c(\"lon\",\"lat\")\n```\n:::\n\nExtracting variable from the original merged raster (30 meters resolution)\n\n::: {.cell}\n\n```{.r .cell-code}\ndf1 = lapply(soil_variables_list, extract, coords@coords)\nas.data.frame(df1) %>% \n  mutate(subject =wm_data2_uni$subject) %>% \n  cbind(longitude=wm_data2_uni$longitude, \n        latitude=wm_data2_uni$latitude) %>% \n  write.csv(\"soil_images/extracted_soil_data.csv\",row.names = F)\n```\n:::\n\n",
    "supporting": [
      "code_soil_variables_white-mold_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": [],
    "engineDependencies": {},
    "preserve": {},
    "postProcess": null
  }
}