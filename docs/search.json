[
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About this study",
    "section": "",
    "text": "Kaique S. Alves1,2; Denis A. Shah3; Helene. R. Dillard4; Emerson M. Del Ponte1; Sarah J. Pethybridge2*\n\n1 Departamento de Fitopatologia, Universidade Federal de Viçosa, Viçosa, MG 36570-900, Brazil\n2 Plant Pathology & Plant-Microbe Biology Section, School of Integrative Plant Science, Cornell University, Geneva, NY 14456, USA\n3 Department of Plant Pathology, Kansas State University, Manhattan, KS 66506, USA\n4 College of Agricultural and Environmental Sciences, University of California, Davis, CA 95616, USA\n*Corresponding author: Sarah. J. Pethybridge\nEmail: sjp277@cornell.edu"
  },
  {
    "objectID": "about.html#summary",
    "href": "about.html#summary",
    "title": "About this study",
    "section": "Summary",
    "text": "Summary\nIn the study we use machine learning interpretation for untangling effects of weather and soil variables on the white mold prevalence in snap bean filds of New York. White mold is a monocyclic plant disease caused by the Ascomycete Sclerotinia sclerotiorum, and it has the reputation of being one the most destructive disease around the world."
  },
  {
    "objectID": "about.html#original-article",
    "href": "about.html#original-article",
    "title": "About this study",
    "section": "Original article",
    "text": "Original article\n\n\n\n\n\n\nThis repository contains the data and code for our article:\n\n\n\nAlves, K.S., Shah, D.A., Dillard, H.R., Del Ponte, E.M., Pethybridge, S.J. (YYYY) Data fusion and machine learning for untangling the effects of the environment on plant disease epidemics.Name of journal/book https://doi.org/xxx/xxx"
  },
  {
    "objectID": "about.html#read-the-preprint",
    "href": "about.html#read-the-preprint",
    "title": "About this study",
    "section": "Read the Preprint",
    "text": "Read the Preprint\n\n\n\n\n\n\nOur pre-print is online on the OSF preprint server:\n\n\n\nAlves, K.S., Shah, D.A., Dillard, H.R., Del Ponte, E.M., Pethybridge, S.J. (YYYY) Machine learning model interpretation for investigating environmental effects on plant disease epidemics. OSF, Accessed 23 June 2022. Online at https://doi.org/xxx/xxx"
  },
  {
    "objectID": "about.html#research-compendium",
    "href": "about.html#research-compendium",
    "title": "About this study",
    "section": "Research compendium",
    "text": "Research compendium\n\n\n\n\n\n\nPlease cite this research compendium as:\n\n\n\nAlves, K.S., Shah, D.A., Dillard, H.R., Del Ponte, E.M., Pethybridge, S.J. (2022) Research compendium: Data fusion and machine learning for untangling the effects of the environment on plant disease epidemics. OSF, Accessed 24 Apr 2022. Online at https://doi.org/10.17605/OSF.IO/V53PY"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "About this repository",
    "section": "",
    "text": "This repository contains the codes used to obtain and analyze the data used in a research study. Read about the study here.\nThe analyses code were written using R version 4.2.0 and scripted on Quarto (.qmd) documents. Follow instruction on the Get Started page of the Quarto website to run the scripts included in this repository.\n\n\n\n\n\n\nReseach compendium\n\n\n\nThe full research compendium with data and scripts used for this study is stored in an Open Science Framework repository and can be accessed here. Download the FULL repository and run the analysis in your machine.\n\n\n\n\n\n\n\n\nAbout the Data\n\n\n\nIn the research repository, the directories containing the soil, weather, white mold are compressed (data_era5.zip,soil_images.zip, data_white-mold.zip). You should unzip these files in the main directory to be able to reproduce the analysis."
  },
  {
    "objectID": "index.html#licensing",
    "href": "index.html#licensing",
    "title": "About this repository",
    "section": "Licensing",
    "text": "Licensing\nCode: MIT year: 2022, copyright holder: Kaique S. Alves"
  },
  {
    "objectID": "index.html#repository-maintainer",
    "href": "index.html#repository-maintainer",
    "title": "About this repository",
    "section": "Repository maintainer",
    "text": "Repository maintainer\nKaique S. Alves\n\nD.Sc candidate in the Plant Pathology graduate program from Universidade Federal de Viçosa in Brazil.\nVisiting Scholar in the EVADE program of the Plant Pathology & Plant-Microbe Biology Section, School of Integrative Plant Science, Cornell University.\n\nPersonal website | GitHub | Google Scholar"
  },
  {
    "objectID": "code_weather_white-mold.html",
    "href": "code_weather_white-mold.html",
    "title": "Weather data",
    "section": "",
    "text": "About R packages\n\n\n\nMake sure to have all R packages installed before running the analysis described in this website.\n\n\n\nlibrary(tidyverse)\nlibrary(cowplot)\nlibrary(patchwork)\nlibrary(raster)\nlibrary(spatstat)\nlibrary(KrigR)\nlibrary(lubridate)\nlibrary(sf)\nlibrary(viridis)\nlibrary(ggthemes)\nlibrary(terra)\nlibrary(MetBrewer)"
  },
  {
    "objectID": "code_weather_white-mold.html#white-mold-data",
    "href": "code_weather_white-mold.html#white-mold-data",
    "title": "Weather data",
    "section": "White mold data",
    "text": "White mold data\n\n\n\n\n\n\nAbout the Data\n\n\n\nIn the research repository, the directories containing the soil, weather, white mold are compressed (data_era5.zip,soil_images.zip, data_white-mold.zip). You should unzip these files in the main directory to be able to reproduce the analysis.\n\n\n\nwm_data = read.csv(\"data_white-mold/WhiteMoldSurveyWrangledData.csv\")\n\n\nRemoving missing coordinates\n\nwm_data2 = wm_data %>% \n  filter(!is.na(latitude))  \n\n\n\nNames of the counties in the dataset\n\ncounties = unique(wm_data2$county)\ncounties\n\n[1] \"Genesee\"    \"Niagara\"    \"Orleans\"    \"Livingston\" \"Wyoming\"   \n[6] \"Ontario\"    \"Yates\"      \"Chautauqua\" \"Monroe\"    \n\ncentral_ny = c(\"wyoming\", \"livingston\",\"ontario\",\"yates\")\n\n\n\nPloting the location of each field\n\n#covert the names to lowercase\nmap_snap_fun = function(yearr){\ncounties_lc = tolower(counties)\n\nny_map_data = map_data('county', region = 'new york')\n\nsnap_map = ny_map_data %>% \n  filter(subregion %in% counties_lc) %>%\n  mutate(region2 = case_when(subregion %in% central_ny ~ \"Central lakes\",\n                            !subregion %in% central_ny ~ \"Great lakes\")) %>% \n  ggplot()+\n  geom_polygon(data = ny_map_data,\n               aes(x=long, y = lat, group = group),\n               fill= \"white\",\n               color = \"black\",\n               size =0.3)+\n  geom_polygon(aes(x=long, y = lat, group = group, fill=region2),\n               # fill= \"gray90\",\n               color = \"black\",\n               size =0.3)+\n  geom_point(data = wm_data2 %>% \n               group_by(subject) %>% \n               filter(dap == max(dap),\n                       !is.na(wm)) %>%\n               ungroup() %>% \n               filter(year == yearr)  , \n                size = 0.4,\n             aes(longitude,latitude, color = wm>0))+\n  coord_map(xlim = c(-80,-76.7),\n            ylim = c(41.8, 43.5))+\n  scale_fill_manual(values = c(\"gray85\", \"gray70\"))+\n  scale_color_colorblind(labels = c(\"Absent\", \"Present\"))+\n  guides(color = guide_legend(override.aes = list(size=3)),\n         fill = \"none\")+\n  theme_minimal()+\n  labs(x = \"Longitude\",\n       y = \"Latitude\",\n       fill = \"Climate division\",\n       color = \"White mold\",\n       title = paste(yearr))+\n  # facet_wrap(~year, ncol = 1)+\n  theme(legend.position = \"right\",\n        legend.text = element_text(size=7),\n        axis.title = element_text(size=7),\n        axis.text = element_text(size=7),\n        plot.title = element_text(size=10))\nsnap_map\n}\n\n\nny_map_data = map_data('county', region = 'new york')\ncounties_lc = tolower(counties)\nny_map = ny_map_data %>% \n  filter(subregion %in% counties_lc) %>% \n  mutate(region2 = case_when(subregion %in% central_ny ~ \"Central lakes\",\n                            !subregion %in% central_ny ~ \"Great lakes\")) %>% \n  ggplot()+\n  geom_polygon(data = ny_map_data,\n               aes(x=long, y = lat, group = group),\n               fill= \"white\",\n               color = \"black\",\n               size =0.3\n               )+\n  geom_polygon(aes(x=long, y = lat, group = group, fill=region2),\n               # fill= \"gray90\",\n               color = \"black\",\n               size =0.3)+\n  annotate(\"rect\", xmin = -80, xmax = -76.5,\n                   ymin = 41.8, ymax = 43.5,\n           color = \"black\",\n           size = 0.3,\n           alpha = 0)+\n  # scale_size_manual(values = c(0.1,0.3))+\n  # coord_map(xlim = c(-80,-73),\n            # ylim = c(40, 45))+\n  coord_map()+\n   scale_fill_manual(values = c(\"gray85\", \"gray70\"))+\n  theme_void()+\n  labs(x = \"Longitude\",\n       y = \"Latitude\",\n       fill = \"Climate division\")+\n  theme(legend.position = c(0.1,0.8))\nny_map\n\n\n\n\n\n  (map_snap_fun(yearr = \"2006\") +\n   map_snap_fun(yearr = \"2007\")+\n   map_snap_fun(yearr = \"2008\")+plot_layout(ncol = 2, guides = 'collect')&\n     theme(legend.position = \"bottom\",\n           legend.justification = c(\"left\",\"center\"))) +\n  (ny_map+plot_layout(guides = 'keep')) +\n\n  # plot_layout(ncol = 2)+\n  plot_annotation(tag_levels = \"A\")&\n  theme(legend.text = element_text(size=6),\n        legend.title = element_text(size=8),\n        legend.key.size = unit(0.4, 'cm'))\n\n\n\nggsave(\"figs/maps/maps_fields.png\", dpi= 900, height = 6, width = 7, bg = \"white\")"
  },
  {
    "objectID": "code_weather_white-mold.html#era5",
    "href": "code_weather_white-mold.html#era5",
    "title": "Weather data",
    "section": "ERA5",
    "text": "ERA5\n\nERA5-Land hourly data from 1950 to present Description\n\n0.1° x 0.1°; Native resolution is 9 km\nGlobal\nHourly\nJanuary 1950 to present\n\nERA5 hourly data on pressure levels from 1979 to present Description\n\nReanalysis: 0.25° x 0.25°\nGlobal\nHourly\n1979 to present\n\nAgrometeorological indicators from 1979 to present derived from reanalysis Description\n\n0.1° x 0.1°\nGlobal\nDaily\n1979 to present\n\nThere is a package for downloading the data using R: link"
  },
  {
    "objectID": "code_weather_white-mold.html#importing-data",
    "href": "code_weather_white-mold.html#importing-data",
    "title": "Weather data",
    "section": "Importing data",
    "text": "Importing data\nHere I load the data for each data variable and gather into a single raster object.\n\n2m temperature\n\n\n\n\n\n\n\nt2m_all = raster::stack(\"data_era5/era5_NY_2006-2008.nc\", varname = \"t2m\")\n\n\n\n2m dewpoint temperature\n\n\n\n\n\n\n\nd2m_all = raster::stack(\"data_era5/era5_NY_2006-2008.nc\", varname = \"d2m\")\n\n\n\nSurface pressure\n\n\n\n\n\n\n\nsp_all = raster::stack(\"data_era5/era5_NY_2006-2008.nc\", varname = \"sp\")\n\n\n\nsoil moisture\n\n\n\n\n\n\n\nswvl1_all = raster::stack(\"data_era5/era5_NY_2006-2008.nc\", varname = \"swvl1\")\n\n\n\nsoil temperature\n\nstl1_all = raster::stack(\"data_era5/era5_NY_2006-2008_2.nc\", varname = \"stl1\")"
  },
  {
    "objectID": "code_weather_white-mold.html#kringing-test",
    "href": "code_weather_white-mold.html#kringing-test",
    "title": "Weather data",
    "section": "Kringing Test",
    "text": "Kringing Test\nKriniging was performed following this tutorial\n\nWeather data\nHere I load the temperature data, select one layer (time and day) and plot it together with the New York map\n\nr <- raster::stack(\"data_era5/era5_NY_2006-2008.nc\", varname = \"t2m\")\na = r$X2008.05.01.00.00.00\nraster::plot(a)\npoints(wm_data2$longitude, wm_data2$latitude)\nmaps::map('county', region = 'new york', col = \"#5E610B\", add = TRUE)\n\n\n\n\n\n\nNY shapefile\nWe will need the New York shapefile to download the digital elevation map, which should be used for kriging. I also filter only the counties that have been surveyed for white mold.\n\nDir.StateShp <- file.path(\"data_era5/test\")# file.path(\"shape_files/nc_files\")\n\n ny_shape1 = readOGR(\"shape_files/cugir-007865/cugir-007865/cty036.shp\")\n\nOGR data source with driver: ESRI Shapefile \nSource: \"G:\\.shortcut-targets-by-id\\1tp3HzkoBOZ0949rE6UQ-y3_WEWrnsmPw\\WhiteMoldSurvey\\01-Kaique\\01-Repository\\shape_files\\cugir-007865\\cugir-007865\\cty036.shp\", layer: \"cty036\"\nwith 67 features\nIt has 80 fields\n\n ny_shape = ny_shape1[ny_shape1$NAME %in% c(unique(wm_data2$county)\n                                            # \"Yates\", \"Steuben\",\"Allegany\", \"Cattaraugus\",\"Erie\"\n                                            ),] \n\nplot(ny_shape)\npoints(wm_data2$longitude, wm_data2$latitude,pch = 19)\n\n\n\n\n\n\nMasking\nHere we make make a mask to filter only the data for the selected counties.\nThe KrigR::mask_Shape() function is diferent from the raster::mask(). The KrigR::mask_Shape() create a new raster object with all cells in the original raster which are at least partially covered by the supplied shapefile. The raster::mask() removes the cells that are partially covered by the shapefile.\nNote that the KrigR::mask_Shape() returns a raster filled with 1 (a11). So I transform that raster to a polygon object (a21) and use it as shapefile to mask all the datasets from now on.\n\n# Create a raster covering the selected counties. Note that all cells has the value 1\na11 = mask_Shape(a, ny_shape)\n\n# create a polygon from the previous raster file (this is going to be our mask fot the all datasets) \na21 = rasterToPolygons(a11, dissolve=T)\n\nLoading required namespace: rgeos\n\n\nWarning in rasterToPolygons(a11, dissolve = T): package rgeos is not available.\nCannot dissolve\n\n# Mask our example dataset\na2 = mask(a,a21)\n\npar(mfrow=c(1,3))\nplot(a11, main = \"NULL raster file\")\nplot(a21, main = \"Mask\")\nplot(a2, main = \"Masked raster data\")\n\n\n\n\n\nori_data_df = as.data.frame(a2, xy = T) \ncolnames(ori_data_df)[3] <- \"values\"\nori_g= ori_data_df %>% \n  filter(!is.na(values)) %>% \n  ggplot()+\n  geom_tile(aes(x, y, fill = values))+\n  geom_polygon(data = ny_shape1,\n              aes(x=long, y = lat, group = group),\n               fill= NA,\n               color = \"black\")+\n  scale_fill_viridis(option=\"B\")+\n  coord_map(xlim = c(-80,-76.8), ylim = c(41.8,43.5))+\n  geom_point(data = wm_data2,\n             shape = 21,\n             color = \"white\",\n             fill = \"black\", \n             aes(longitude,latitude))+\n  labs(x = \"Longitude\",\n       y = \"Latitude\",\n       title= \"Era5 original\")+\n  theme_minimal()\n\nRegions defined for each Polygons\n\nori_g\n\n\n\n\n\n\nDownloading Digital elevation model (DEM)\nFunction to plot the DEM\n\nsource(\"functions/Plot_Covs.R\")\n\nDownloading DEM\n\nCovs_ls <- download_DEM(\n  Train_ras = a2,\n  Target_res = .02,\n  Shape = ny_shape,\n  Dir = Dir.StateShp,\n  Keep_Temporary = TRUE\n)\n\nPlot_Covs(Covs_ls)\n\n\n\n\n\nVisualization\n…Using ggplot2\n\nas.data.frame(Covs_ls[[2]], xy = T) %>%\n  filter(!is.na(DEM)) %>% \n  ggplot() +\n  geom_tile(aes(x,y,fill = DEM))+\n  geom_polygon(data = ny_shape1,\n              aes(x=long, y = lat, group = group),\n               fill= NA,\n               color = \"black\")+\n   geom_point(data = wm_data2, size = 0.1,\n             aes(longitude,latitude))+\n  scale_fill_gradientn(colors=met.brewer(\"Homer2\", direction = -1))+\n  coord_map(xlim = c(-80,-76.8), ylim = c(41.8,43.5))+\n  labs(x = \"Longitude\",\n       y = \"Latitude\",\n       title= \"Era5 original\")+\n  theme_void()+\n  theme(legend.position = \"none\")\n\nRegions defined for each Polygons\n\n\n\n\nggsave(\"figs/maps/elevation.png\", dpi = 600, height = 5, width = 7, bg = \"white\")\n\n\n\n\nKringing\nThis function performs kriging of the weather variables as function of the DEM data\n\nKrigStart <- Sys.time() \n\nState_Krig <- krigR(\n  Data = a2, # what to krig\n  Covariates_coarse = Covs_ls[[1]], # covariates at training resolution\n  Covariates_fine = Covs_ls[[2]], # covariates at target resolution\n  Keep_Temporary = FALSE, # delete temporary krigs of layers\n  Cores = 1, # only run this on 1 core\n  FileName = \"State_Shape.nc\", # save the finished file as this _t2m_2008.nc\n  Dir = Dir.StateShp # where to save the output\n)\n\nCommencing Kriging\n\n\nKriging of remaining 0 data layers should finish around: 2022-06-23 14:58:46\n\n\n\n  |                                                                            \n  |                                                                      |   0%\n  |                                                                            \n  |======================================================================| 100%\n\nKrigStop <- Sys.time() \nKrigStop-KrigStart\n\nTime difference of 1.942145 secs\n\nplot(State_Krig$Kriging_SE)\n\n\n\n\n\n\nVisualization\n\nKrigs = State_Krig$Kriging_Output\n# Krigs = State_Krig$Kriging_SE\nKrig_df <- as.data.frame(Krigs[[1]], xy = TRUE)\ncolnames(Krig_df)[3] <- \"values\"\n\n\n\nkrig_g = Krig_df %>% \n  filter(!is.na(values)) %>% \n  ggplot()+\n  geom_tile(aes(x, y, fill = values))+\n  geom_polygon(data = ny_shape1,\n              aes(x=long, y = lat, group = group),\n               fill= NA,\n               color = \"black\")+\n  scale_fill_viridis(option=\"B\")+\n  # scale_color_viridis(option=\"B\")+\n  geom_point(data = wm_data2,\n             shape = 21,\n             color = \"white\",\n             fill = \"black\",\n             aes(longitude,latitude))+\n  coord_map()+\n  labs(x = \"Longitude\",\n       y = \"Latitude\",\n       title= \"Era5 kriged\")\n\nRegions defined for each Polygons\n\nori_g + krig_g +\n  plot_layout(ncol = 1) &\ncoord_map(xlim = c(-80,-76.8), ylim = c(41.8,43.5))&\ntheme_minimal()\n\nCoordinate system already present. Adding new coordinate system, which will replace the existing one.\n\n\nCoordinate system already present. Adding new coordinate system, which will replace the existing one."
  },
  {
    "objectID": "code_weather_white-mold.html#daily-summaries",
    "href": "code_weather_white-mold.html#daily-summaries",
    "title": "Weather data",
    "section": "Daily summaries",
    "text": "Daily summaries\n\npar(mfrow=c(1,3))\nplot(mean(t2m_all[[1:24]]))\nmaps::map('county', region = 'new york', col = \"#5E610B\", add = TRUE)\nplot(min(t2m_all[[1:24]]))\nmaps::map('county', region = 'new york', col = \"#5E610B\", add = TRUE)\nplot(max(t2m_all[[1:24]]))\nmaps::map('county', region = 'new york', col = \"#5E610B\", add = TRUE)\n\n\n\n\n\n# days_in_month(month)\nyear = 2006:2008\nmonth = 4:10\nday = 01:31\nhour = as.numeric(seq(0,23,1))\ndata_era5 = expand_grid(year, month, day) %>% \n  dplyr::filter(month != 4 | day != 31,\n         month != 6 | day != 31,\n         month != 9 | day != 31)%>% \n  unite(date, year, month, day,sep=\"-\",remove = F ) %>% \n  mutate(date = as.Date(date))\n\nFunction for calculating the summaries\n\nmean_raster = function(i, stack_obj){\n  mean(stack_obj[[i:(i+23)]])\n}\nmin_raster = function(i, stack_obj){\n  min(stack_obj[[i:(i+23)]])\n}\nmax_raster = function(i, stack_obj){\n  max(stack_obj[[i:(i+23)]])\n}\n\n\nLapply\n\ndays_i = seq(1,length(data_era5$day)*24,by = 24)\ntime_start = Sys.time()\n\n# dew point\naa1 = lapply(days_i, mean_raster, stack_obj= d2m_all)\nd2m_mean_daily_stack = mask(stack(aa1), a21)\nwriteCDF(rast(d2m_mean_daily_stack),\n         \"data_era5/daily_summaries/d2m_mean_daily.nc\",\n         overwrite=TRUE)\n# temperature\n### mean\naa2 = lapply(days_i, mean_raster, stack_obj= t2m_all)\nt2m_mean_daily_stack = mask(stack(aa2), a21)\nwriteCDF(rast(t2m_mean_daily_stack),\n         \"data_era5/daily_summaries/t2m_mean_daily.nc\",\n         overwrite=TRUE)\n### minimum\naa3 = lapply(days_i, min_raster, stack_obj= t2m_all)\nt2m_min_daily_stack = mask(stack(aa3), a21)\nwriteCDF(rast(t2m_min_daily_stack),\n         \"data_era5/daily_summaries/t2m_min_daily.nc\",\n         overwrite=TRUE)\n### maximum\naa4 = lapply(days_i, max_raster, stack_obj= t2m_all)\nt2m_max_daily_stack = mask(stack(aa4), a21)\nwriteCDF(rast(t2m_max_daily_stack),\n         \"data_era5/daily_summaries/t2m_max_daily.nc\",\n         overwrite=TRUE)\n\n\n# Surface pressure\naa5 = lapply(days_i, mean_raster, stack_obj= sp_all)\nsp_mean_daily_stack = mask(stack(aa5), a21)\nwriteCDF(rast(sp_mean_daily_stack),\n         \"data_era5/daily_summaries/sp_mean_daily.nc\",\n         overwrite=TRUE)\n\n# Soil moisture\naa6 = lapply(days_i, mean_raster, stack_obj= swvl1_all)\nswvl1_mean_daily_stack = mask(stack(aa6), a21)\nwriteCDF(rast(swvl1_mean_daily_stack),\n         \"data_era5/daily_summaries/swvl1_mean_daily.nc\",\n         overwrite=TRUE)\n\n# soil temperature\naa7 = lapply(days_i, mean_raster, stack_obj= stl1_all)\nstl1_mean_daily_stack = mask(stack(aa7), a21)\nwriteCDF(rast(stl1_mean_daily_stack),\n         \"data_era5/daily_summaries/stl1_mean_daily.nc\",\n         overwrite=TRUE)\n\ntime_end = Sys.time()\ntime_end -time_start\n\n\nplot(stl1_mean_daily_stack$X1)\nmaps::map('county', region = 'new york',  add = TRUE)\n\n\n\n\n\n\nDownload DEM\n\nDir.krigd_var <- file.path(\"data_era5/kriged\")\nCovs_ls <- download_DEM(\n  Train_ras = d2m_mean_daily_stack,\n  Target_res = .02,\n  Shape = ny_shape,\n  Dir = Dir.krigd_var,\n  Keep_Temporary = TRUE\n)\n\nPlot_Covs(Covs_ls)\n\n\n\n\n\n\nKriging the daily summaries\n\nDew point\n\n# time_start =Sys.time()\n\nd2m_mean_daily_Krig <- krigR(\n  Data = d2m_mean_daily_stack, # what to krig\n  Covariates_coarse = Covs_ls[[1]], # covariates at training resolution\n  Covariates_fine = Covs_ls[[2]], # covariates at target resolution\n  Keep_Temporary = FALSE, # delete temporary krigs of layers\n  Cores = 8, # only run this on 1 core\n  FileName = \"d2m_mean_daily_krig.nc\", # save the finished file as this\n  Dir = Dir.krigd_var # where to save the output\n)\n\n\n\nMean Temeperature\n\nt2m_mean_daily_Krig <- krigR(\n  Data = t2m_mean_daily_stack, # what to krig\n  Covariates_coarse = Covs_ls[[1]], # covariates at training resolution\n  Covariates_fine = Covs_ls[[2]], # covariates at target resolution\n  Keep_Temporary = FALSE, # delete temporary krigs of layers\n  Cores = 8, # only run this on 1 core\n  FileName = \"t2m_mean_daily_Krig.nc\", # save the finished file as this\n  Dir = Dir.krigd_var # where to save the output\n)\n\n\n\nMinimum temperature\n\nt2m_min_daily_Krig <- krigR(\n  Data = t2m_min_daily_stack, # what to krig\n  Covariates_coarse = Covs_ls[[1]], # covariates at training resolution\n  Covariates_fine = Covs_ls[[2]], # covariates at target resolution\n  Keep_Temporary = FALSE, # delete temporary krigs of layers\n  Cores = 8, # only run this on 1 core\n  FileName = \"t2m_min_daily_Krig.nc\", # save the finished file as this\n  Dir = Dir.krigd_var # where to save the output\n)\n\n\n\nMaximum temperature\n\nt2m_max_daily_Krig <- krigR(\n  Data = t2m_max_daily_stack, # what to krig\n  Covariates_coarse = Covs_ls[[1]], # covariates at training resolution\n  Covariates_fine = Covs_ls[[2]], # covariates at target resolution\n  Keep_Temporary = FALSE, # delete temporary krigs of layers\n  Cores = 8, # only run this on 1 core\n  FileName = \"t2m_max_daily_Krig.nc\", # save the finished file as this\n  Dir = Dir.krigd_var # where to save the output\n)\n\n\n\nSurface pressure\n\nsp_mean_daily_Krig <- krigR(\n  Data = sp_mean_daily_stack, # what to krig\n  Covariates_coarse = Covs_ls[[1]], # covariates at training resolution\n  Covariates_fine = Covs_ls[[2]], # covariates at target resolution\n  Keep_Temporary = FALSE, # delete temporary krigs of layers\n  Cores = 8, # only run this on 1 core\n  FileName = \"sp_mean_daily_Krig.nc\", # save the finished file as this\n  Dir = Dir.krigd_var # where to save the output\n)\n\n\n\nSoil temperature\n\nstl1_mean_daily_Krig <- krigR(\n  Data = stl1_mean_daily_stack, # what to krig\n  Covariates_coarse = Covs_ls[[1]], # covariates at training resolution\n  Covariates_fine = Covs_ls[[2]], # covariates at target resolution\n  Keep_Temporary = FALSE, # delete temporary krigs of layers\n  Cores = 8, # only run this on 1 core\n  FileName = \"stl1_mean_daily_Krig.nc\", # save the finished file as this\n  Dir = Dir.krigd_var # where to save the output\n)\n# time_end = Sys.time()\n# time_end -time_start\n\n\n\nSoil moisture\n\nswvl1_mean_daily_Krig <- krigR(\n  Data = swvl1_mean_daily_stack, # what to krig\n  Covariates_coarse = Covs_ls[[1]], # covariates at training resolution\n  Covariates_fine = Covs_ls[[2]], # covariates at target resolution\n  Keep_Temporary = FALSE, # delete temporary krigs of layers\n  Cores = 8, # only run this on 1 core\n  FileName = \"swvl1_mean_daily_Krig.nc\", # save the finished file as this\n  Dir = Dir.krigd_var # where to save the output\n)\n# time_end = Sys.time()\n# time_end -time_start\n\nplot(swvl1_mean_daily_Krig$Kriging_SE$var1.stdev.1)\n\n\nkrigR_temporal = function(i, data){\ncov1 = stl1_mean_daily_stack[[i]]\nnames(cov1) = c(\"soilT\")\n\ncov2 = stl1_mean_daily_Krig$Kriging_Output[[i]]\nnames(cov2) = c(\"soilT\")\nCovs_ls2 = list(cov1, cov2)\n\ndatax = crop(swvl1_mean_daily_stack[[i]],a21)\n\nxxxx <- krigR(\n  Data = data[[i]], # what to krig\n  Covariates_coarse = Covs_ls2[[1]], # covariates at training resolution\n  Covariates_fine = Covs_ls2[[2]], # covariates at target resolution\n  Keep_Temporary = FALSE, # delete temporary krigs of layers\n  KrigingEquation = \"ERA ~ soilT\",\n  Cores = 8, # only run this on 1 core\n  FileName = \"swvl1_mean_daily_Krig2.nc\", # save the finished file as this\n  Dir = Dir.krigd_var # where to save the output\n)\nreturn(xxxx$Kriging_Output)\n}\nnlayers = length(swvl1_mean_daily_stack@layers)\nswvl1_mean_daily_Krig2 = stack(lapply(X = 1:nlayers, FUN = krigR_temporal,data = swvl1_mean_daily_stack ))\nwriteCDF(rast(swvl1_mean_daily_Krig2),\n         \"data_era5/kriged/swvl1_mean_daily_Krig2.nc\",\n         overwrite=TRUE)\n\n\nd2m_mean_daily_Krig = stack(\"data_era5/kriged/d2m_mean_daily_Krig.nc\")\nt2m_mean_daily_Krig = stack(\"data_era5/kriged/t2m_mean_daily_Krig.nc\")\nt2m_min_daily_Krig = stack(\"data_era5/kriged/t2m_min_daily_Krig.nc\")\nt2m_max_daily_Krig = stack(\"data_era5/kriged/t2m_max_daily_Krig.nc\")\nsp_mean_daily_Krig = stack(\"data_era5/kriged/sp_mean_daily_Krig.nc\")\nswvl1_mean_daily_Krig = stack(\"data_era5/kriged/swvl1_mean_daily_Krig.nc\")\nstl1_mean_daily_Krig = stack(\"data_era5/kriged/stl1_mean_daily_Krig.nc\")\n\n\n\n\nPloting the kingued maps (first layer)\n\npar(mfrow=c(2,4))\nplot(t2m_mean_daily_Krig$X1, main = \"Mean Temp\")\nplot(t2m_min_daily_Krig$X1, main = \"Min Temp\")\nplot(t2m_max_daily_Krig$X1, main = \"Max Temp\")\nplot(d2m_mean_daily_Krig$X1, main = \"Dew Point\")\nplot(sp_mean_daily_Krig$X1, main = \"Surface Pressure\")\nplot(swvl1_mean_daily_Krig$X1, main = \"Soil Moisture\")\nplot(stl1_mean_daily_Krig$X1, main = \"Soil Temp\")\n\n\n\n\nUsing ggplot\n\n# t2m_max_daily_stack\nKrigs = t2m_max_daily_stack$X1\nKrig_df <- as.data.frame(Krigs[[1]], xy = TRUE)\ncolnames(Krig_df)[3] <- \"values\"\n\nmax_t_ori = Krig_df %>% \n  filter(!is.na(values)) %>% \n  ggplot()+\n  geom_polygon(data = ny_shape1,\n              aes(x=long, y = lat, group = group),\n               fill= \"white\",\n               color = \"black\")+\n  geom_tile(aes(x, y, fill = values-273.15))+\n  geom_polygon(data = ny_shape1,\n              aes(x=long, y = lat, group = group),\n               fill= NA,\n               color = \"black\")+\n  scale_fill_viridis(option=\"B\", limits = c(5,18),breaks =seq(5, 18, by = 3))+\n  # scale_color_viridis(option=\"B\")+\n  geom_point(data = wm_data2,\n             shape = 21,\n             color = \"white\",\n             fill = \"black\",\n             aes(longitude,latitude))+\n  coord_map(xlim = c(-80,-76.8), ylim = c(41.8,43.5))+\n  labs(x = \"Longitude\",\n       y = \"Latitude\",\n       fill = \"Max Temperature (°C)\",\n       title= \"Era5 Native Resolution (0.1° x 0.1°)\")\n\nRegions defined for each Polygons\nRegions defined for each Polygons\n\n# max_t_ori\n\n\nKrigs = t2m_max_daily_Krig$X1\nKrig_df <- as.data.frame(Krigs[[1]], xy = TRUE)\ncolnames(Krig_df)[3] <- \"values\"\n\n\n\nmax_t_krig = Krig_df %>% \n  filter(!is.na(values)) %>% \n  ggplot()+\n  geom_polygon(data = ny_shape1,\n              aes(x=long, y = lat, group = group),\n               fill= \"white\",\n               color = \"black\")+\n  geom_tile(aes(x, y, fill = values-273.15))+\n  geom_polygon(data = ny_shape1,\n              aes(x=long, y = lat, group = group),\n               fill= NA,\n               color = \"black\")+\n  scale_fill_viridis(option=\"B\", limits = c(5,18), breaks =seq(5, 18, by = 3))+\n  # scale_color_viridis(option=\"B\")+\n  geom_point(data = wm_data2,\n             shape = 21,\n             color = \"white\",\n             fill = \"black\",\n             aes(longitude,latitude))+\n  coord_map(xlim = c(-80,-76.8), ylim = c(41.8,43.5))+\n  labs(x = \"Longitude\",\n       y = \"Latitude\",\n       fill = \"Max Temperature (°C)\",\n       title= \"Era5 Kriged (0.02° x 0.02°)\")\n\nRegions defined for each Polygons\nRegions defined for each Polygons\n\nmax_t_ori + max_t_krig +\n  plot_layout(ncol = 2, guides = \"collect\") &\n  theme_map()&\n  theme(legend.position = \"bottom\",\n        legend.text = element_text(size = 9))\n\n\n\n# ggsave(\"figs/max_t.png\",dpi=900, height = 8, width=14, bg = \"white\")\n\n\n\nRelative humidity\nHow to calculate relative humidity here link and here link\n\\[RH = \\frac{es(d2m)}{es(t2m)}*100\\]\n\\(es()\\) is Saturation vapor pressure and can be calculated as\n\\[es(T) = \\alpha_1*exp( \\alpha_3*(\\frac{T-t0}{T-\\alpha_4}))\\],\nwhere \\(T\\) is the temperature, \\(\\alpha_1 = 611.21\\), \\(\\alpha_2 = 17.502\\), \\(\\alpha_3 = 32.19\\).\nUsing these resources, I build the function to calculates RH from Temperature and dew point.\n\nes =function(Temp){\nt0 = 273.16\n  \nalpha1 = 611.21\nalpha3 = 17.502\nalpha4 = 32.19\n\nalpha1*exp( alpha3*((Temp-t0)/(Temp-alpha4)))\n\n}\n\n#test\nTdp = 14+273.15\nT2m = 31+273.15\nes(Tdp)/es(T2m)*100\n\n[1] 35.55801\n\n\nCreating the raster object of relative humidity\n\nlayer_i = 1:nlayers(d2m_mean_daily_Krig)\n\ncalculate_RH = function(i, d2m_stack, t2m_stack){\n  es(d2m_stack[[i]])/es(t2m_stack[[i]])*100\n}\n\nlist_rh = lapply(layer_i, calculate_RH, d2m_stack = d2m_mean_daily_Krig,t2m_stack= t2m_mean_daily_Krig)\n\nrh_mean_daily_Krig = brick(list_rh)\n\n\n\nwriteCDF(rast(rh_mean_daily_Krig),\n         \"data_era5/kriged/rh_mean_daily_Krig.nc\",\n         overwrite=TRUE)\n\n\nrh_mean_daily_Krig = stack(\"data_era5/kriged/rh_mean_daily_Krig.nc\")\nplot(rh_mean_daily_Krig$X1, main = \"Relative Humidity\")"
  },
  {
    "objectID": "code_weather_white-mold.html#extracting-data",
    "href": "code_weather_white-mold.html#extracting-data",
    "title": "Weather data",
    "section": "Extracting data",
    "text": "Extracting data\n\nwm_data2_uni = wm_data2 %>% \n  group_by(subject) %>% \n  slice(1L)\n\n\ncoords<-data.frame(lon=wm_data2_uni$longitude, lat=wm_data2_uni$latitude)\ncoordinates(coords)<-c(\"lon\",\"lat\")\n\n\nDew point\n\n\next_d2m = extract(d2m_mean_daily_Krig, coords)\ncolnames(ext_d2m) = as.character(data_era5$date)\next_d2m_coord = cbind(longitude=wm_data2_uni$longitude, \n                      latitude=wm_data2_uni$latitude,\n                      ext_d2m )\n\nd2m_mean_wm = as.data.frame(ext_d2m_coord) %>%\n  mutate(subject =wm_data2_uni$subject) %>% \n  pivot_longer(3:644,\n               values_to = \"d2m\",\n               names_to = \"date\")%>% \n  mutate(date = as.Date(date))\nd2m_mean_wm\n\n# A tibble: 241,392 × 5\n   longitude latitude subject date         d2m\n       <dbl>    <dbl>   <int> <date>     <dbl>\n 1     -77.9     42.9       1 2006-04-01  282.\n 2     -77.9     42.9       1 2006-04-02  271.\n 3     -77.9     42.9       1 2006-04-03  276.\n 4     -77.9     42.9       1 2006-04-04  270.\n 5     -77.9     42.9       1 2006-04-05  266.\n 6     -77.9     42.9       1 2006-04-06  272.\n 7     -77.9     42.9       1 2006-04-07  275.\n 8     -77.9     42.9       1 2006-04-08  268.\n 9     -77.9     42.9       1 2006-04-09  268.\n10     -77.9     42.9       1 2006-04-10  270.\n# … with 241,382 more rows\n\n\n\nMean Temperature\n\n\next_t2m_mean = extract(t2m_mean_daily_Krig, coords)\ncolnames(ext_t2m_mean) = as.character(data_era5$date)\next_t2m_mean_coord = cbind(longitude=wm_data2_uni$longitude,\n                           latitude=wm_data2_uni$latitude,\n                           ext_t2m_mean)\n\nt2m_mean_wm = as.data.frame(ext_t2m_mean_coord) %>%\n  mutate(subject =wm_data2_uni$subject)%>%\n  pivot_longer(3:644,\n               values_to = \"t2m_mean\",\n               names_to = \"date\")%>% \n  mutate(date = as.Date(date))\n\n\nMax Temperature\n\n\next_t2m_max = extract(t2m_max_daily_Krig, coords)\ncolnames(ext_t2m_max) = as.character(data_era5$date)\next_t2m_max_coord = cbind(longitude=wm_data2_uni$longitude,\n                           latitude=wm_data2_uni$latitude,\n                           ext_t2m_max)\n\nt2m_max_wm = as.data.frame(ext_t2m_max_coord) %>%\n  mutate(subject =wm_data2_uni$subject)%>%\n  pivot_longer(3:644,\n               values_to = \"t2m_max\",\n               names_to = \"date\")%>% \n  mutate(date = as.Date(date))\n\n\nMin Temperature\n\n\next_t2m_min = extract(t2m_min_daily_Krig, coords)\ncolnames(ext_t2m_min) = as.character(data_era5$date)\next_t2m_min_coord = cbind(longitude=wm_data2_uni$longitude,\n                           latitude=wm_data2_uni$latitude,\n                           ext_t2m_min)\n\nt2m_min_wm = as.data.frame(ext_t2m_min_coord) %>%\n  mutate(subject =wm_data2_uni$subject)%>%\n  pivot_longer(3:644,\n               values_to = \"t2m_min\",\n               names_to = \"date\")%>% \n  mutate(date = as.Date(date))\n\n\nPressure\n\n\next_sp = extract(sp_mean_daily_Krig, coords)\ncolnames(ext_sp) = as.character(data_era5$date)\next_sp_coord = cbind(longitude=wm_data2_uni$longitude, \n                      latitude=wm_data2_uni$latitude,\n                      ext_sp )\n\nsp_mean_wm = as.data.frame(ext_sp_coord) %>%\n  mutate(subject =wm_data2_uni$subject)%>%\n  pivot_longer(3:644,\n               values_to = \"sp\",\n               names_to = \"date\")%>% \n  mutate(date = as.Date(date))\n\n\nSoil moisture\n\n\next_sm = extract(swvl1_mean_daily_Krig, coords)\ncolnames(ext_sm) = as.character(data_era5$date)\next_sm_coord = cbind(longitude=wm_data2_uni$longitude, \n                      latitude=wm_data2_uni$latitude,\n                      ext_sm )\n\nsm_mean_wm = as.data.frame(ext_sm_coord)%>%\n  mutate(subject =wm_data2_uni$subject) %>%\n  pivot_longer(3:644,\n               values_to = \"sm\",\n               names_to = \"date\")%>% \n  mutate(date = as.Date(date))\n\n\nRelative humidity\n\n\next_rh = extract(rh_mean_daily_Krig, coords)\ncolnames(ext_rh) = as.character(data_era5$date)\next_rh_coord = cbind(longitude=wm_data2_uni$longitude,\n                     latitude=wm_data2_uni$latitude,\n                     ext_rh )\n\nrh_mean_wm = as.data.frame(ext_rh_coord)%>%\n  mutate(subject =wm_data2_uni$subject)%>%\n  pivot_longer(3:644,\n               values_to = \"rh\",\n               names_to = \"date\") %>% \n  mutate(date = as.Date(date))\n\n\nSoil temperature\n\n\next_st = extract(stl1_mean_daily_Krig, coords)\ncolnames(ext_st) = as.character(data_era5$date)\next_st_coord = cbind(longitude=wm_data2_uni$longitude,\n                     latitude=wm_data2_uni$latitude,\n                     ext_st )\n\nst_mean_wm = as.data.frame(ext_st_coord) %>% \n  mutate(subject =wm_data2_uni$subject)%>%\n  pivot_longer(3:644,\n               values_to = \"st\",\n               names_to = \"date\") %>% \n  mutate(date = as.Date(date))\n\nBinding data sets\n\nweather_all_wm = d2m_mean_wm %>%\n  bind_cols(t2m_mean_wm[,5],\n            t2m_max_wm[,5],\n            t2m_min_wm[,5],\n            sp_mean_wm[,5],\n            sm_mean_wm[,5],\n            rh_mean_wm[,5],\n            st_mean_wm[,5])\nweather_all_wm\n\n# A tibble: 241,392 × 12\n   longitude latitude subject date         d2m t2m_mean t2m_max t2m_min     sp\n       <dbl>    <dbl>   <int> <date>     <dbl>    <dbl>   <dbl>   <dbl>  <dbl>\n 1     -77.9     42.9       1 2006-04-01  282.     284.    289.    281. 97567.\n 2     -77.9     42.9       1 2006-04-02  271.     279.    285.    273. 98578.\n 3     -77.9     42.9       1 2006-04-03  276.     282.    290.    277. 97387.\n 4     -77.9     42.9       1 2006-04-04  270.     277.    284.    273. 97250.\n 5     -77.9     42.9       1 2006-04-05  266.     273.    277.    270. 97416.\n 6     -77.9     42.9       1 2006-04-06  272.     276.    283.    273. 97868.\n 7     -77.9     42.9       1 2006-04-07  275.     278.    281.    275. 97193.\n 8     -77.9     42.9       1 2006-04-08  268.     274.    277.    271. 97920.\n 9     -77.9     42.9       1 2006-04-09  268.     275.    282.    270. 98859.\n10     -77.9     42.9       1 2006-04-10  270.     278.    288.    272. 99093.\n# … with 241,382 more rows, and 3 more variables: sm <dbl>, rh <dbl>, st <dbl>\n\n\n\nSaving data\n\ndata_full = weather_all_wm %>%\n  dplyr::select(-latitude, -longitude) %>% \n full_join(wm_data2, by = \"subject\") \n  \nwrite.csv(data_full, \"data_white-mold/data_model_plus_weather.csv\",row.names = F)\n\n\ndata_full = read.csv(\"data_white-mold/data_model_plus_weather.csv\") %>% \n  mutate(date = as.Date(date),\n         sampling.date =  as.Date(sampling.date),\n         planting.date = as.Date(planting.date))\n\nfilter between planting and sampling dates\n\ndata_fill_filtered = data_full %>% \n  filter(date >= (planting.date-30) & date <= sampling.date)\n\n\nwrite.csv(data_fill_filtered, \"data_white-mold/data_model_plus_weather_filtered.csv\",row.names = F)\n\n\ndata_fill_filtered = read.csv(\"data_white-mold/data_model_plus_weather_filtered.csv\")"
  },
  {
    "objectID": "code_soil_variables_white-mold.html",
    "href": "code_soil_variables_white-mold.html",
    "title": "Soil data",
    "section": "",
    "text": "About R packages\n\n\n\nMake sure to have all R packages installed before running the analysis described in this website.\n\n\n\nlibrary(tidyverse)\nlibrary(cowplot)\nlibrary(patchwork)\nlibrary(daymetr)\nlibrary(raster)\nlibrary(spatstat)\nlibrary(KrigR)\nlibrary(lubridate)\nlibrary(sf)\nlibrary(viridis)\nlibrary(terra)\nlibrary(XPolaris)\nlibrary(MetBrewer)"
  },
  {
    "objectID": "code_soil_variables_white-mold.html#white-mold-data",
    "href": "code_soil_variables_white-mold.html#white-mold-data",
    "title": "Soil data",
    "section": "White mold data",
    "text": "White mold data\nLoading white mold data. We are going to use the field coordinates (latitude and longitude) to extract the data from the rasters of soil variables.\n\n\n\n\n\n\nAbout the Data\n\n\n\nIn the research repository, the directories containing the soil, weather, white mold are compressed (data_era5.zip,soil_images.zip, data_white-mold.zip). You should unzip these files in the main directory to be able to reproduce the analysis.\n\n\n\nwm_data = read.csv(\"data_white-mold/WhiteMoldSurveyWrangledData.csv\")\n\n\nRemoving missing coordinates\nThere are some missing coordinates in the dataset. Here we remove them.\n\nwm_data2 = wm_data %>% \n  filter(!is.na(latitude))"
  },
  {
    "objectID": "code_soil_variables_white-mold.html#soil-variables",
    "href": "code_soil_variables_white-mold.html#soil-variables",
    "title": "Soil data",
    "section": "Soil variables",
    "text": "Soil variables\n\nLocations\nSetting up the coordinated of each quadrat we need to download the soil data\n\n# exkansas\nny_locations = data.frame(ID = c(\"NY1\",\"NY2\",\"NY3\",\"NY4\",\"NY5\",\"NY6\",\"NY7\",\"NY8\"),\n                          lat  = c(42,  42,  42, 42, 43,   43,   43,   43),\n                          long = c(-77, -78,-79, -80,-77, -78.0,-79.0, -80))\n\nxplot(locations = ny_locations)+\n  geom_point(data = wm_data2 , size = 0.3,\n             aes(longitude,latitude))+\n  coord_map( xlim = c(-81,-75),\n             ylim = c(41.5,44.5))\n\nCoordinate system already present. Adding new coordinate system, which will replace the existing one.\n\n\n\n\n# max(wm_data2$longitude)\n\n\n\nDownload soil data\n\nny_images <- ximages(locations = ny_locations,\n                      statistics = c('mean'),\n                      variables = c('ph','om','clay',\"sand\",\"silt\",\"bd\", \"hb\",\"n\",\"alpha\",\"ksat\",\"lambda\",\"theta_r\",\"theta_s\"),\n                      layersdepths = c('0_5'),\n                      localPath = file.path(\"soil_images\"))\n\nHere we read the metadata of the downloaded data. It containg the informatino regarding the directory of each downloaded file.\n\n\nMerge images\n\nOrganic matter\nWe are going to filter only the lines contain information regarding Organic matter\n\nom_df_images = ny_images %>% \n  filter(variables == \"om\")\n\nAs you can notice in the next figure, the raster objects are downloaded in separate raster of 01 degree size\n\n# read all files for organic matter\nom_stack = lapply(om_df_images$local_file, brick)\n\n\npar(mfrow = c(2,4))\n\nfor(i in 1:length(om_stack)){\nplot(om_stack[[i]])\n}\n\n\n\n\nTherefore, we use the function merge() to create a single raster object covering the whole study region\n\nom_ny_raster =merge(om_stack[[1]],\n                    om_stack[[2]],\n                    om_stack[[3]],\n                    om_stack[[4]],\n                    om_stack[[5]],\n                    om_stack[[6]],\n                    om_stack[[7]],\n                    om_stack[[8]])\n\nplot(exp(om_ny_raster))\n\n\n\n\n\n\n\nAutomatization\nInstead of doing the above step for each variable by hand, here we created a function to do all the steps automatically.\n\nget_soil_var = function(var, data){\n  data_filtered = data %>% \n  filter(variables == var)\n\nstack_list = lapply(data_filtered$local_file, brick)\n  \n  \n  merged_raster = merge(stack_list[[1]],\n                    stack_list[[2]],\n                    stack_list[[3]],\n                    stack_list[[4]],\n                    stack_list[[5]],\n                    stack_list[[6]],\n                    stack_list[[7]],\n                    stack_list[[8]]\n                    )\n  return(merged_raster)\n}\n\nsoil_vars = c('ph','om','clay',\"sand\",\"silt\",\"bd\", \"hb\",\"n\",\"alpha\",\"ksat\",\"lambda\",\"theta_r\",\"theta_s\")\n\nselected_vars = c('ph','om','clay',\"sand\",\"silt\",\"bd\",\"theta_r\",\"theta_s\")\n\n\nsoil_variables_list = lapply(soil_vars,get_soil_var, data = ny_images)\nnames(soil_variables_list) = soil_vars\n\nsaveRDS(soil_variables_list, \"soil_images/list_soil_variables_raster.rds\")\n\n\naggre_var_list = lapply(soil_variables_list, aggregate,fact=30)\n\nsaveRDS(aggre_var_list, \"soil_images/list_soil_variables_raster_aggregated.rds\")\n\n\n\nPlot soil maps\n\nNY shape file\nLoading New York state shape file.\n\nny_shape1 = readOGR(\"shape_files/cugir-007865/cugir-007865/cty036.shp\")\n\nOGR data source with driver: ESRI Shapefile \nSource: \"G:\\.shortcut-targets-by-id\\1tp3HzkoBOZ0949rE6UQ-y3_WEWrnsmPw\\WhiteMoldSurvey\\01-Kaique\\01-Repository\\shape_files\\cugir-007865\\cugir-007865\\cty036.shp\", layer: \"cty036\"\nwith 67 features\nIt has 80 fields\n\n\n\n\nCropping raster files\nWe use the function lappy() to crop all variables’ rasters using the NY shape file as a mask.\n\naggre_var_list2 = lapply(aggre_var_list, mask, ny_shape1)\n\nThen here we create a function for ploting the soil maps.\n\nactual_var_names = c(\"Soil pH in water\", \"Soil organic matter\",\"Clay\",\"Sand\",\"Silt\",\"Bulk density\",\"Residual soil water content\",\"Saturated soil water content\")\nactual_var_symbol = c(\"pH\", \"OM\",\"Clay\",\"Sand\",\"Silt\",\"BD\",\"\\u03B8r\",\"\\u03B8s\")\nactual_var_units = c(\"\", \"(%)\",\"(%)\",\"(%)\",\"(%)\",\"(g/cm³)\",\"(m³/m³)\",\"(m³/m³)\")\n\nplot_gg_raster =  function(X,raster, var){\n  # actual_var_names[X]\n\nif(var[X] == \"om\"){xx=1}else{xx = 0}\n  \nas.data.frame(raster[[var[X]]], xy = T) %>%\n    filter(layer !=\"NaN\", x< -76.8) %>%\n  mutate(layer = case_when(xx ==1~ exp(layer),\n                           xx ==0~ layer)) %>% \n    ggplot(aes())+\n    geom_raster(aes(x, y, fill = layer))+\n    scale_fill_viridis(option =\"B\",guide = guide_colorbar(barwidth = 0.2, barheight =5 ))+\n    geom_polygon(data = ny_shape1,\n                 aes(x=long, y = lat, group = group),\n                 fill= NA,\n                 size =0.2,\n                 alpha = 0.5,\n                 color = \"white\")+\n  # geom_point(data = wm_data2 , size = 0.1,color = \"white\",\n  #            aes(longitude,latitude))+\n    coord_quickmap(xlim = c(-80,-76.8), ylim = c(42,43.35))+\n    theme_map()+\n    labs(title =paste(\"    \",actual_var_names[X]),\n         fill = paste(actual_var_symbol[X],actual_var_units[X]))\n}\n\n# selected_vars\n# aggre_var_list[[1]]\n# plot_gg_raster(1,aggre_var_list2, var = selected_vars[1] )\n\n\n\nCombo soil maps\nHere we plot all maps into a single combo fiure\n\ndo.call(patchwork::wrap_plots, lapply(X =1:length(selected_vars) , FUN =plot_gg_raster, raster = aggre_var_list2, var = selected_vars))+\n  plot_layout(ncol = 2)+\n  plot_annotation(tag_levels = \"A\")&\n  theme(legend.position = \"right\",\n        legend.text = element_text(size = 5),\n        legend.title = element_text(size = 5),\n        plot.title =  element_text(size = 7, face = \"bold\"))\n\nRegions defined for each Polygons\nRegions defined for each Polygons\nRegions defined for each Polygons\nRegions defined for each Polygons\nRegions defined for each Polygons\nRegions defined for each Polygons\nRegions defined for each Polygons\nRegions defined for each Polygons\n\n\n\n\nggsave(\"figs/maps/soil_maps.png\", dpi = 900, height = 7, width = 7, bg = \"white\")"
  },
  {
    "objectID": "code_soil_variables_white-mold.html#extract-variables-to-location",
    "href": "code_soil_variables_white-mold.html#extract-variables-to-location",
    "title": "Soil data",
    "section": "Extract variables to location",
    "text": "Extract variables to location\n\nwm_data2_uni = wm_data2 %>% \n  group_by(subject) %>% \n  slice(1L)\n\nSelecting coordinate columns from the white mold data set\n\ncoords<-data.frame(lon=wm_data2_uni$longitude, lat=wm_data2_uni$latitude)\ncoordinates(coords)<-c(\"lon\",\"lat\")\n\nExtracting variable from the original merged raster (30 meters resolution)\n\ndf1 = lapply(soil_variables_list, extract, coords@coords)\nas.data.frame(df1) %>% \n  mutate(subject =wm_data2_uni$subject) %>% \n  cbind(longitude=wm_data2_uni$longitude, \n        latitude=wm_data2_uni$latitude) %>% \n  write.csv(\"soil_images/extracted_soil_data.csv\",row.names = F)"
  },
  {
    "objectID": "code_fda_white-mold.html",
    "href": "code_fda_white-mold.html",
    "title": "Functional data analysis",
    "section": "",
    "text": "About R packages\n\n\n\nMake sure to have all R packages installed before running the analysis described in this website.\n\n\n\nlibrary(tidyverse)\nlibrary(cowplot)\nlibrary(lemon)\nlibrary(ggthemes)\nlibrary(patchwork)\nlibrary(mgcv)\nlibrary(mgcViz)\nlibrary(itsadug)\nlibrary(tidymv)\ntheme_set(theme_half_open(font_size = 12))"
  },
  {
    "objectID": "code_fda_white-mold.html#generalized-additive-models-gam",
    "href": "code_fda_white-mold.html#generalized-additive-models-gam",
    "title": "Functional data analysis",
    "section": "Generalized additive models (GAM)",
    "text": "Generalized additive models (GAM)\n\nExample for RH\n\nFiltering data for until 60 days post planting\n\n\ngam_data = wm_data %>%\n  mutate(dap =as.numeric(dap),\n         wm = as.factor(wm)) %>% \n  filter(dap<=60)\n\n\nMixed-effect GAM model\n\ngam_mtemp = gam(rh ~ wm +s(dap, by =wm, bs = \"bs\", m=4, k =17 )+ s(subject, bs=\"re\") + s(subject,dap, bs = \"re\"),\n                method = \"REML\",\n                 data = gam_data )\n\nsummary(gam_mtemp)\n\n\nFamily: gaussian \nLink function: identity \n\nFormula:\nrh ~ wm + s(dap, by = wm, bs = \"bs\", m = 4, k = 17) + s(subject, \n    bs = \"re\") + s(subject, dap, bs = \"re\")\n\nParametric coefficients:\n            Estimate Std. Error t value Pr(>|t|)    \n(Intercept)  69.2706     0.1118 619.736   <2e-16 ***\nwm1           0.1044     0.1434   0.728    0.467    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nApproximate significance of smooth terms:\n                    edf Ref.df       F p-value    \ns(dap):wm0     8.500476  9.727  60.089  <2e-16 ***\ns(dap):wm1     7.556624  8.676  25.327  <2e-16 ***\ns(subject)     0.998893  1.000 932.465  <2e-16 ***\ns(subject,dap) 0.008296  1.000   0.001   0.789    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nR-sq.(adj) =  0.0532   Deviance explained = 5.37%\n-REML = 1.1741e+05  Scale est. = 105.4     n = 31322\n\n\n\n\nPredicting curves\n\npredict_gam(gam_mtemp ,\n            exclude_terms = list(\"s(subject)\", \"s(subject,dap)\" ),\n            values = list(subject = NULL)) %>%\n  # filter(subject == 1)+\n  ggplot(aes(dap,fit, color = wm, fill = wm))+\n  annotate(\"rect\",ymin = -Inf, ymax = Inf, xmin = 35, xmax = 50, fill = \"steelblue\", alpha = 0.2)+\n  geom_vline(xintercept = 0, color = \"gray\", linetype = \"dashed\")+\n  geom_ribbon(aes( ymin= fit - 1.96*se.fit, ymax = fit + 1.96*se.fit),\n              linetype =0, \n              alpha = 0.1)+\n  geom_line(size = 1 )+\n  scale_x_continuous(breaks = seq(-30, 70, by =10))+\n  scale_color_colorblind(labels = c( \"Non-prevalent\",\"Prevalent\"))+\n  scale_fill_colorblind(labels = c( \"Non-prevalent\",\"Prevalent\"))+\n  labs(x = \"Days relative to planting date\",\n       fill = \"\",\n       color =\"\")+\n  theme(legend.position = \"top\")\n\n\n\n\n\n\nGet differences\n\ngg_temp_diff= get_smooths_difference(gam_mtemp, dap, list(wm = c(\"1\", \"0\")), series_length = 500)\n\n\n\ngg_temp_diff %>%\n  ggplot(aes(dap, difference, group = group))+\n  annotate(\"rect\",ymin = -Inf, ymax = Inf, xmin = 35, xmax = 50, fill = \"steelblue\", alpha = 0.2)+\n  \n  geom_vline(xintercept = 0, color = \"gray\", linetype = \"dashed\")+\n  geom_ribbon(aes(ymin = CI_lower, ymax = CI_upper, fill = sig_diff), alpha = 1)+\n  geom_line(size =1, color = \"white\")+\n  geom_hline(yintercept = 0, color = \"gray\", linetype = \"dashed\")+\n  # scale_fill_colorblind()+\n  scale_fill_manual(values = c(\"black\", \"red\"))+\n  scale_x_continuous(breaks = seq(-30, 70, by =10))+\n  labs(x = \"Days relative to planting date\",\n       y = \"Difference\",\n       fill = \"\",\n       color =\"\")\n\n\n\n# ggsave(\"figs/diff_gam.png\", dpi = 600, width = 6, height = 3, bg = \"white\")"
  },
  {
    "objectID": "code_fda_white-mold.html#all-variables",
    "href": "code_fda_white-mold.html#all-variables",
    "title": "Functional data analysis",
    "section": "All variables",
    "text": "All variables\nDefining variable names for graphs\n\nvars = c(\"d2m\", \"t2m_mean\" ,\"t2m_max\" , \"t2m_min\" ,\"st\",\"sm\" ,\"sp\" ,\"rh\" )\n\nvar_fulnames = c(\"Dew point (°C)\",\"Mean temperature (°C)\", \"Max. temperature (°C)\",\"Min. temperature (°C)\",\"Soil temperature (°C)\",\"Soil Moisture (m³/m³)\", \"Surface pressure (Pa)\",\"Relative Humidity (%)\")\n\n# \"gdd\",\"Growing degree days\",\n\nThis is a function we built for fitting the GAM model for each variable. Then we use the lapply() function to run it to all variables and store into a list object.\n\nglmvars = function(var, data){\n  \nform =   as.formula(\n  paste(var,\"~wm +s(dap, by =wm, bs = 'bs', m=4, k =17 )+ s(subject, bs='re') + s(subject,dap, bs = 're')\")\n  )\ngam_model = gam(form,\n                 # random = list(subject=~1),\n                method = \"REML\",\n                 data = data ) \n\nreturn(gam_model)\n \n}\n\ngam_list = lapply(vars,glmvars, gam_data )\nnames(gam_list) = vars\n\n\nPredicted curves\nThis function was designed to plot the predicted smooth curves for each variable.\n\nplot_curves_fda = function(i, model, var){\n  predict_gam(model[[i]] ,\n            exclude_terms = list(\"s(subject)\", \"s(subject,dap)\" ),\n            values = list(subject = NULL)) %>%\n  # filter(subject == 1)+\n  ggplot(aes(dap,fit, color = wm, fill = wm))+\n  annotate(\"rect\",ymin = -Inf, ymax = Inf, xmin = 35, xmax = 50, fill = \"#ce9ea1\", alpha = 0.3)+\n  geom_vline(xintercept = 0, color = \"black\", linetype = \"dashed\", size = 0.2)+\n  geom_ribbon(aes( ymin= fit - 1.96*se.fit, ymax = fit + 1.96*se.fit),\n              linetype =0, \n              alpha = 0.5)+\n  geom_line(size = .8)+\n  scale_color_colorblind(labels = c( \"Non-prevalent\",\"Prevalent\"))+\n  scale_fill_colorblind(labels = c( \"Non-prevalent\",\"Prevalent\"))+\n  scale_x_continuous(breaks = seq(-30, 60, by =15))+\n  scale_y_continuous(n.breaks = 5)+\n  labs(x = \"Days relative to planting date\",\n       y = paste(var[i]),\n       fill = \"\",\n       color =\"\",\n       title = paste(var[i]))+\n  theme(legend.position = \"top\")\n}\nX =1:length(vars)\n\n\nVisualization\nHere we plot all the curves in a combo figure\n\ndo.call(patchwork::wrap_plots,\n        lapply(X, plot_curves_fda, model = gam_list, var = var_fulnames))+\n  plot_layout(guides = \"collect\",\n              ncol = 2)+\n  plot_annotation(tag_levels = \"A\")&\n  theme(axis.text = element_text(size=6),\n        axis.title = element_text(size=6),\n        plot.title = element_text(size=7),\n        legend.position = \"bottom\")\n\n\n\n#save figure\nggsave(\"figs/fda_figs/curves_gam_fda.png\", dpi = 600,  width = 5, height = 6, bg = \"white\") \n\n\n\nDifference curves\nThis function get the difference between smooth curves and plot using ggplot2().\n\nggplot_diff = function(i, model, var){\n  \nggdiff = get_smooths_difference(model[[i]], dap, list(wm = c(\"1\", \"0\")),series_length = 1500)\n\nggdiff %>%\n  ggplot(aes(dap, difference))+\n  annotate(\"rect\",ymin = -Inf, ymax = Inf, xmin = 35, xmax = 50, fill = \"#ce9ea1\", alpha = 0.3)+\n  geom_vline(xintercept = 0, color = \"black\", linetype = \"dashed\", size = 0.2)+\n  geom_ribbon(aes(ymin = CI_lower, ymax = CI_upper, fill = sig_diff, group = group), alpha = 1)+\n  geom_line(size =0.5, color = \"white\")+\n  geom_hline(yintercept = 0, color = \"black\", linetype = \"dashed\", size = 0.2)+\n  scale_fill_manual(values = c(\"FALSE\" = \"#707181\",\n                              \"TRUE\" = \"steelblue\"))+##cd2b2d\n  scale_x_continuous(breaks = seq(-30, 60, by =15))+\n  labs(x = \"Days relative to planting date\",\n       y = \"Difference\",\n       title = var[[i]],\n       fill = \"Sig. Diff.\",\n       color =\"\")+\n  theme(plot.title = element_text(size = 12))\n\n}\nX =1:length(vars)\n\n\nVisualization\n\ndo.call(patchwork::wrap_plots,\n        lapply(X, ggplot_diff, model = gam_list, var = var_fulnames))+\n  plot_layout(guides = \"collect\",\n              ncol = 2)+\n  plot_annotation(tag_levels = \"A\")&\n  theme(axis.text = element_text(size=7),\n        axis.title = element_text(size=6),\n        plot.title = element_text(size=9),\n        legend.position = \"bottom\")\n\n\n\n# save figure\nggsave(\"figs/fda_figs/diff_gam.png\", dpi = 900, width = 5, height = 6, bg = \"white\")"
  },
  {
    "objectID": "code_fda_white-mold.html#saving-data",
    "href": "code_fda_white-mold.html#saving-data",
    "title": "Functional data analysis",
    "section": "Saving data",
    "text": "Saving data\nThis function store the difference values into a data.frame. We use the lapply() function to get the difference for the selected variables\n\ndiff_fun = function(i, model, var){\n difs =  get_smooths_difference(model[[i]], dap, list(wm = c(\"1\", \"0\")), series_length = 91) %>% \n    mutate(var = var[[i]])\nreturn(difs)\n}\n\nX =1:length(vars)\nall_diffs = bind_rows(lapply(X, diff_fun, gam_list,var = vars ))\nall_diffs\n\n\n  \n\n\n\nHere we save (using the write.csv() function) the data with the periods in time that we found significant differences between smoothed curves.\n\ngam_data %>% \n  dplyr::select(subject, dap, wm, d2m, t2m_mean, t2m_max, t2m_min, sp, sm, st, rh, dpd) %>% \n  pivot_longer(4:12, \n               values_to = \"value\",\n               names_to = \"var\") %>% \n  full_join(\n    all_diffs %>%\n      dplyr::select(dap,var, sig_diff)\n  ) %>% \n  write.csv(\"data_white-mold/data_fda_sig_diff.csv\",row.names = F)"
  },
  {
    "objectID": "code_boosting_white-mold.html",
    "href": "code_boosting_white-mold.html",
    "title": "XgBoost model",
    "section": "",
    "text": "About R packages\n\n\n\nMake sure to have all R packages installed before running the analysis described in this website.\n\n\n\nlibrary(tidyverse)\nlibrary(tidymodels)\nlibrary(SHAPforxgboost)\nlibrary(cowplot)\nlibrary(lemon)\nlibrary(ggthemes)\nlibrary(ggdist)\nlibrary(patchwork)\nlibrary(rgr)\nlibrary(vip)\nlibrary(pdp)\nlibrary(doParallel)\n\ntheme_set(theme_half_open(font_size = 12))\n\n\n\n\n\n\n\n\n\n\n\nAbout the Data\n\n\n\nIn the research repository, the directories containing the soil, weather, white mold are compressed (data_era5.zip,soil_images.zip, data_white-mold.zip). You should unzip these files in the main directory to be able to reproduce the analysis.\n\n\n\nwm_load = read.csv(\"data_white-mold/data_model_plus_weather_filtered.csv\")\nwm_load\n\n\n  \n\n\n\n\n\n\nwm_data = wm_load %>%\n  #transform these columns into Date format\n  mutate(date = as.Date(date),\n         sampling.date =  as.Date(sampling.date),\n         planting.date = as.Date(planting.date)) %>% \n  \n  # Calculate dap\n  mutate(dap = date-planting.date) %>% \n  # #\n  # # mutate(gddi = ((t2m_max +t2m_min)*0.5)-0) %>%\n  # group_by(subject) %>% \n  # mutate(gdd = cumsum(gddi)) %>% \n  \n  group_by(subject) %>% \n  mutate(wm = (mean(wm, na.rm =T)>0)*1) %>% \n  ungroup() %>% \n  filter(!is.na(wm))\n  \n  \nwm_data\n\n\n  \n\n\n\n\n\n\n\n\nwhite_load_fda = read.csv(\"data_white-mold/data_fda_sig_diff.csv\") %>% \n  filter(dap<=50,\n         dap>=-15)%>% \n  separate(var, into =c(\"var\", \"stats\"), sep =\"_\") %>% \n  mutate(var = toupper(var)\n         # stats = ifelse(is.na(stats),\"\",stats)\n         ) %>% \n  unite(var,var, stats, sep = \" \", na.rm = T) %>% \n  mutate(sig_diff = case_when(var == \"RH\" & dap %in% c(40:50) ~ TRUE,\n                              TRUE ~ sig_diff)) %>% \n  filter(var != \"DPD\")\n\nWarning: Expected 2 pieces. Missing pieces filled with `NA` in 140976 rows [1,\n5, 6, 7, 8, 9, 10, 14, 15, 16, 17, 18, 19, 23, 24, 25, 26, 27, 28, 32, ...].\n\nvar_names = unique(white_load_fda$var)\n\n\nDefining periods\n\nThis function define and name the periods that the functional curves significatively difered from zero or not.\n\ndefine_interval = function(variable, data){\n\ntest_df = data  %>%\n  filter(var == variable ) %>%\n  group_by(subject,var, wm) %>% \n  mutate(sig_diff = sig_diff*1) \n\n\nperiod = numeric(length(-15:50))\nperiod_all = numeric( length(-15:50)*length(unique(test_df$subject)) )\n\ninter = 1:66\nfor(j in unique(test_df$subject)){\n  \n per = 1 \n \n filt_df = test_df %>% \n      filter(subject == j)\n \n  # current = filt_df$sig_diff[1]\n  period[1]= per\n  \n  for(i in 1:(length(-15:49))){\n  \n   if(filt_df$sig_diff[i+1] == filt_df$sig_diff[i]){\n    per = per\n   }else{\n    per = per+1\n  }\n  \n  period[i+1]= per\n  \n\n  }\n period_all[inter] =period\n inter = inter+66\n}\noptions(dplyr.summarise.inform = FALSE)\nfinal_df = test_df %>%\n  ungroup() %>% \n  mutate(periodo = period_all*sig_diff) %>% \n  group_by(subject, wm, periodo) %>%\n  filter(periodo !=0) %>% \n  mutate(per_name = paste0(\"(\",min(dap),\" to \", max(dap), \" dap)\")) %>%\n  group_by(subject,per_name, wm) %>%\n  summarise(x = mean(value)) %>%\n  pivot_wider(values_from = `x`,\n              names_from = per_name, \n              names_prefix = paste(variable,\" \"))\n\nreturn(final_df)\n\n}\n\ndata_fda_list = lapply(var_names,define_interval, data =  white_load_fda)\nmerged_fda =  Reduce(function(...) merge(..., all=T), data_fda_list) \n\n\n\n\n\nsoil_df_load =read.csv(\"data_white-mold/extracted_soil_data.csv\") %>% \n  dplyr::select(-longitude, -latitude)\n\n\nCentered log-ratio transformation for sand, silt, and clay\n\n\nsoil_comp = as.matrix(soil_df_load[c(\"clay\",\"sand\",\"silt\")])\n\nlog_sand_clay = log(soil_comp[,\"sand\"]/soil_comp[,\"clay\"])\nlog_silt_clay = log(soil_comp[,\"silt\"]/soil_comp[,\"clay\"])\n\ntexture =  data.frame(log_sand_clay, log_silt_clay)\n\n\nsoil_df_load %>% \n  bind_cols(texture) %>% \n  filter(clay<30) %>% \n  ggplot(aes(clay,log_silt_clay , color =silt))+\n  geom_point()+\n  geom_hline(yintercept = c(1.1,1.3))+\n  scale_color_gradient(low =\"#1e88e5ff\",\n                       high = \"#ff0d57ff\",\n                       n.breaks = 5,\n                       guide = guide_colorbar(barwidth = 10,\n                                              barheight = 0.3))+\n  labs(color = \"Silt (%)\",\n       y = \"log(Silt/Clay)\",\n       x = \"Clay (%)\")+\n  theme(legend.position = \"top\")+\n  \n\n\n\nsoil_df_load %>% \n  bind_cols(texture) %>% \n  filter(clay<30) %>% \n  ggplot(aes(clay,log_sand_clay , color =sand))+\n  geom_point()+\n  scale_color_gradient(low =\"#1e88e5ff\",\n                       high = \"#ff0d57ff\",\n                       n.breaks = 5,\n                       guide = guide_colorbar(barwidth = 10,\n                                              barheight = 0.3))+\n  labs(color = \"Sand (%)\",\n       y = \"log(Sand/Clay)\",\n       x = \"Clay (%)\")+\n  theme(legend.position = \"top\")+\n  \n  plot_annotation(tag_levels = \"A\")\n\n\n\n\n\nsoil_df = soil_df_load %>% \n  dplyr::select(-sand, -silt, -clay) %>% \n  bind_cols(texture)\n\n\ntidy_soil_df = soil_df %>% \n  full_join(merged_fda[c(\"subject\", \"wm\")]) %>% \n  filter(!is.na(wm)) %>% \n  dplyr::select(-subject, -hb,-n, -alpha,-lambda, -ksat) %>%  \n  pivot_longer(1:7, \n               names_to = \"variable\",\n               values_to = \"values\") %>%\n  mutate(variable = case_when(variable == \"theta_r\" ~ \"Residual soil water content (m³/m³)\",\n                              variable == \"theta_s\" ~ \"Saturated soil water content (m³/m³)\",\n                              variable == \"om\" ~ \"Soil organic matter (%)\",\n                              variable == \"ph\" ~ \"Soil pH\",\n                              variable == \"bd\" ~ \"Soil bulk density g/cm³\",\n                              variable == \"log_sand_clay\" ~ \"log(Sand/Clay)\",\n                              variable == \"log_silt_clay\" ~ \"log(Silt/Clay)\"))\n\nJoining, by = \"subject\"\n\n\n\ntidy_soil_df %>% \n  ggplot(aes(as.factor(wm), values, color = values))+\n  ggforce::geom_sina(\n    alpha = 0.8,\n    color = \"gray\",\n    maxwidth =0.5\n    )+\n  geom_boxplot(\n    fill = NA,\n    outlier.colour = NA,\n    width =0.5,\n    color = \"black\"\n    )+\n  facet_rep_wrap(\n    ~variable,\n    scales = \"free_y\",\n    ncol = 2,\n    strip.position = \"left\",\n    labeller = label_wrap_gen(width=20)\n    )+\n  scale_x_discrete(labels = c(\"1\" = \"Prevalent\",\n                              \"0\" = \"Non-prevalent\" ))+\n  labs(x = \"White mold prevalence\",\n       y = \"\")+\n  theme(\n    strip.background = element_blank(),\n    strip.placement = \"outside\",\n    axis.text = element_text(size=7)\n    )\n\n\n\n# ggsave(\"figs/xboost_figs/soil_data.png\", dpi = 900, height = 7, width = 6, bg = \"white\")  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nwm_original = wm_data %>% \n  group_by(subject) %>% \n  summarise(elevation = unique(elevation),\n            `Planting date` = format(mean(planting.date), \"%j\"))\n\n\n\n\n\nml_data_fda =soil_df %>%\n  full_join(merged_fda) %>% \n  full_join(wm_original) %>% \n  filter(!is.na(wm)) %>% \n  mutate(wm= factor(wm, levels =c(\"1\", \"0\")),\n         `Planting date` = as.numeric(`Planting date`)) %>%\n  ungroup() %>% \n  dplyr::select(-subject, -hb,-n, -alpha,-lambda, -ksat) %>% \n  relocate(wm)\n\nJoining, by = \"subject\"\nJoining, by = \"subject\"\n\nwrite.csv(ml_data_fda, \"data_white-mold/data_tidy_xgboost.csv\", row.names = F)\n\n\n\n\n\n\nsetting up parallel computation\n\n\nlibrary(parallel)\nall_cores <- parallel::detectCores(logical = FALSE)\nregisterDoParallel(cores = all_cores)\n\n\nPreprocessing\n\n\npreprocessing_recipe <- \n  recipes::recipe(wm ~ ., data = ml_data_fda) %>%\n  # convert categorical variables to factors\n  recipes::step_string2factor(all_nominal()) %>%\n  # combine low frequency factor levels\n  recipes::step_other(all_nominal(), threshold = 0.01) %>%\n  # remove no variance predictors which provide no predictive information \n  recipes::step_nzv(all_nominal()) %>%\n  prep()\n\n\nSplitting for Cross Validation\n\n\names_cv_folds <- \n  recipes::bake(\n    preprocessing_recipe, \n    new_data = ml_data_fda#training(wm_split)\n  ) %>%  \n  rsample::vfold_cv(v = 5)\n\n\nXGBoost Model Specification\n\n\nxgboost_model <- \n  parsnip::boost_tree(\n    mode = \"classification\",\n    trees = 5000,\n    min_n = tune(),\n    tree_depth = tune(),\n    mtry = tune(),#<<<<<<<<<\n    learn_rate = tune(),\n    loss_reduction = tune()\n  ) %>%\n    set_engine(\"xgboost\")\n\n\nGrid Specification\n\n\nxgboost_params <- \n  dials::parameters(\n    min_n(),\n    finalize(mtry(), ml_data_fda),#<<<<<<<<<\n    tree_depth(range = c(1L, 5L)),\n    learn_rate(),\n    loss_reduction()\n  )\nset.seed(1)\n\nxgboost_grid <- \n  dials::grid_max_entropy(\n    xgboost_params, \n    size = 60\n  )\nhead(xgboost_grid)\n\n\n  \n\n\n\n\nDefine the Workflow\n\n\nxgboost_wf <- \n  workflows::workflow() %>%\n  add_model(xgboost_model) %>% \n  add_formula(wm ~ .)\n\n\n\nmetrics\n\nxgboost_tuned_fda <- tune::tune_grid(\n  object = xgboost_wf,\n  resamples = ames_cv_folds,\n  grid = xgboost_grid,\n  metrics = yardstick::metric_set(recall, precision, f_meas,accuracy, kap,roc_auc, sens, spec,mn_log_loss),\n  control = tune::control_grid(verbose = TRUE, save_pred = TRUE)\n)\n# ml_data\nsaveRDS(xgboost_tuned_fda, \"xgboost/tuned_grid_fda.RDS\")\n\n\nxgboost_tuned_fda %>% \n  collect_metrics()%>%\n  filter(.metric == \"accuracy\") %>%\n  dplyr::select(mean, mtry:loss_reduction) %>%\n  pivot_longer(mtry:loss_reduction,\n               values_to = \"value\",\n               names_to = \"parameter\"\n  ) %>%\n  ggplot(aes(value, mean, color = parameter)) +\n  geom_point(alpha = 0.8, show.legend = FALSE) +\n  facet_wrap(~parameter, scales = \"free_x\") +\n  labs(x = NULL, y = \"accuracy\")\n\n\n\n\n\n\n\n\nxgboost_best_params <- xgboost_tuned_fda %>% \n  tune::select_best(metric = \"mn_log_loss\")\n\nxgboost_tuned_fda %>% \n  collect_metrics(summarise = TRUE) %>%\n  filter(.config == xgboost_best_params$.config)\n\n\n  \n\n\n\n\nRun best model\n\n\nxgboost_model_final <- xgboost_model %>% \n  finalize_model(xgboost_best_params)\nxgboost_model_final\n\nBoosted Tree Model Specification (classification)\n\nMain Arguments:\n  mtry = 12\n  trees = 5000\n  min_n = 4\n  tree_depth = 5\n  learn_rate = 0.0554118757975475\n  loss_reduction = 1.41284077086654\n\nComputational engine: xgboost \n\n\n\ntrain_processed <- bake(preprocessing_recipe,  new_data = ml_data_fda)\nset.seed(1)\ntrained_model =  xgboost_model_final %>%\n  # fit the model on all the training data\n  fit(\n    formula = wm ~ ., \n    data    = train_processed\n  )\n\n\nCheck the best cuting point\n\n\ntest_cut_point= function(P_cut){\n # P_cut = 0.90 \naccuracy_df = trained_model %>% \n  predict(new_data = train_processed, type = c(\"prob\")) %>%\n  mutate(.pred_class = factor(ifelse(.pred_1>P_cut, 1, 0), levels = c(\"1\",\"0\"))) %>%\n  dplyr::select(-.pred_0,-.pred_1) %>%\n  bind_cols(ml_data_fda) %>%\n  yardstick::accuracy(truth = wm, .pred_class) %>% \n  mutate(cut_point = P_cut)\nreturn(accuracy_df)\n}\ncut_point_df = bind_rows(lapply(X = seq(0.05,0.85, by =0.01), test_cut_point)) \n\nmax_accuracy_point = cut_point_df %>% \n  filter(.estimate == max(.estimate))\nmax_accuracy_point\n\n\n  \n\n\n\n\ncut_point_df%>% \n  ggplot(aes(cut_point, .estimate))+\n  geom_line()+\n  geom_vline(xintercept = max_accuracy_point$cut_point[1])\n\n\n\n\n\n# predict for the training data\ntrain_prediction1 <- trained_model %>% \n  predict(new_data = train_processed, type = c(\"prob\")) %>%\n  # mutate(.pred_class = as.factor(ifelse(.pred_1>max_accuracy_point$cut_point[1], 1, 0))) %>%\n    mutate(.pred_class = factor(ifelse(.pred_1>max_accuracy_point$cut_point[1], 1, 0), levels = c(\"1\",\"0\"))) %>%\n\n  dplyr::select(-.pred_0,-.pred_1) %>%\n  bind_cols(ml_data_fda)\n\nxgboost_score_train1 <- train_prediction1 %>%\n  yardstick::metrics(truth = wm, .pred_class, options = list(accuracy(), kap(), roc_auc())) #%>%\n  # mutate(.estimate = format(round(.estimate, 2), big.mark = \",\"))\nxgboost_score_train1\n\n\n  \n\n\n# trained_model$spec\n\n\n\n\ntrain_prediction1 %>% \n  conf_mat(wm, .pred_class) %>% \n  autoplot(type = \"heatmap\")\n\n\n\n# train_prediction1 %>% \n\n\n\n\n\ntrain_prediction2 <- trained_model %>% \n  predict(new_data = train_processed, type = c(\"prob\")) %>%\n  bind_cols(ml_data_fda)\n\ntrain_prediction2 %>% \n  roc_curve(wm, .pred_1) %>% \n  autoplot()\n\n\n\n\n\n\n\n\nbind_rows(\n  xgboost_score_train1,\ntrain_prediction1 %>% \n  sens(wm, .pred_class),\ntrain_prediction1 %>% \n  spec(wm, .pred_class),\ntrain_prediction1 %>% \n  precision(wm, .pred_class),\ntrain_prediction2 %>% \n  roc_auc(wm, .pred_1),\ntrain_prediction2 %>% \n  mn_log_loss(wm, .pred_1)\n)\n\n\n  \n\n\n# recall, precision, f_meas,accuracy, kap,roc_auc, sens, spec\n\n\ntrained_model2 = trained_model\n# aaaa$data %>% \nxx = trained_model$fit$feature_names\ntrained_model2$fit$feature_names = str_replace(str_replace(xx , \"`\", \"\"), \"`\", \"\")\n# trained_model2$fit$feature_names\n\n\n\n\n\n\naaaa = trained_model2 %>% \n  vip(geom = \"col\", num_features = 30)\n\nvip_fda = aaaa$data %>% \n  mutate(Variable = str_replace(Variable, \"`\", \"\"),\n         Variable = str_replace(Variable, \"`\", \"\"))\n\nas.data.frame(vip_fda) %>% \n  arrange(-Importance) %>%\n  mutate(nr = 1:nrow(vip_fda)) %>% \n  filter(nr <= 10) %>% \n  summarise(sum(Importance))\n\n\n  \n\n\nvar_names12 = vip_fda[1:9,]$Variable\n\n\naaaa$data %>% \n  mutate(Variable = case_when(Variable == \"theta_r\" ~ \"Residual soil water content\",\n                              Variable == \"theta_s\" ~ \"Saturated soil water content\",\n                              Variable == \"om\" ~ \"Soil organic matter\",\n                              Variable == \"ph\" ~ \"Soil pH\",\n                              Variable == \"bd\" ~ \"Soil bulk density\",\n                              Variable == \"log_sand_clay\" ~ \"log(Sand/Clay)\",\n                              # Variable == \"clay\" ~ \"Clay\",\n                              Variable == \"log_silt_clay\" ~ \"log(Silt/Clay)\",\n                              Variable == \"elevation\" ~ \"Elevation\",\n                              TRUE ~ Variable)) %>% \n  arrange(-Importance)  %>%\n  mutate(nr = 1:nrow(vip_fda)) %>% \n  # filter(nr <= 20) %>%\n  mutate(Variable = str_replace(Variable, \"  \", \" \")) %>% \n  ggplot(aes(Importance*100, reorder(Variable,Importance), fill =Importance))+\n  geom_errorbar(aes(xmin = 0, xmax = Importance*100), width = 0)+\n  geom_point(size = 3, shape =21)+\n  scale_fill_viridis_c()+\n  scale_color_viridis_c()+\n  theme(legend.position = \"none\")+\n  labs(x = \"Relative importance (%)\",\n       y = \"\" )\n\n\n\n# ggsave(\"figs/xboost_figs/importance_fda.png\", width = 6,height =6, bg = \"white\")\n\n\n\n\nabout ice curve\n\ninfluence_plot = function(var){\n\nif(var == \"om\"){\n  var1 = \"Soil organic matter\" \n}else if(var == \"theta_r\"){\n    var1 = \"Residual soil water content\"\n    }else if(var ==\"log_silt_clay\" ){\n      var1 = \"log(Silt/Clay)\"\n  }else{var1 = var}  \n  \nplot_i = pdp::partial(trained_model2$fit,\n             pred.var = var,#var[i],\n             train =  subset(ml_data_fda, select = -wm),\n             type = \"classification\",\n             which.class =1L,\n             plot = TRUE,\n             prob =T,\n             alpha = 1,\n             plot.engine = \"ggplot2\")+\n  geom_smooth(se = F, color = \"darkred\", method = \"gam\", formula = y ~ s(x, bs = \"cs\"))+\n  labs(y = \"Probability\",\n       x = paste(var1))\n\nreturn(plot_i)\n}\n\n\ndo.call(patchwork::wrap_plots, lapply(var_names12[1:9],influence_plot))+\n  plot_layout(ncol = 3)+\n  plot_annotation(tag_levels = \"A\")\n\n\n\n# ggsave(\"figs/xboost_figs/partial_fda.png\", width = 9,height =8, bg = \"white\")\n\n\n\n\n\nFinalize workflow\n\n\nsplit_data = make_splits(ml_data_fda,\n            assessment = ml_data_fda)\n\nregisterDoParallel(cores = 1)\n\nset.seed(1)\nfinal_xgb <- finalize_workflow( xgboost_wf, xgboost_best_params) %>% \n  last_fit(split_data, \n           metrics = metric_set(accuracy, roc_auc, mn_log_loss, pr_auc, f_meas, precision, recall))\nfinal_xgb$.metrics\n\n[[1]]\n# A tibble: 7 × 4\n  .metric     .estimator .estimate .config             \n  <chr>       <chr>          <dbl> <chr>               \n1 accuracy    binary         0.969 Preprocessor1_Model1\n2 f_meas      binary         0.922 Preprocessor1_Model1\n3 precision   binary         0.970 Preprocessor1_Model1\n4 recall      binary         0.878 Preprocessor1_Model1\n5 roc_auc     binary         0.998 Preprocessor1_Model1\n6 mn_log_loss binary         0.134 Preprocessor1_Model1\n7 pr_auc      binary         0.992 Preprocessor1_Model1\n\n\nUseful sources : link 1 and link 2\n\nset.seed(1)\nfitted_data <- preprocessing_recipe %>%\n  prep() %>%\n  bake(new_data = ml_data_fda) %>%\n  dplyr::select(-wm)\n# set.seed(1)\nxgb_model_extrac = extract_fit_engine(final_xgb)\nshap_data = fitted_data %>% as.matrix()\ncolnames(shap_data) = xgb_model_extrac$feature_names\n# set.seed(1)\nshap_long = shap.prep(xgb_model = extract_fit_engine(final_xgb),\n                      X_train = shap_data)\n# set.seed(1)\nshap_values = shap.values(xgb_model = extract_fit_engine(final_xgb),\n                      X_train = shap_data)\n\n#plot\nshap.plot.summary(data_long = shap_long,\n                  scientific = F)\n\n\n\n\n\nshap_long_tidy = shap_long %>% \n  mutate(variable = as.character(variable)) %>% \n  mutate(variable = case_when(variable == \"theta_r\" ~ \"Residual soil water content\",\n                              variable == \"theta_s\" ~ \"Saturated soil water content\",\n                              variable == \"om\" ~ \"Soil organic matter\",\n                              variable == \"ph\" ~ \"Soil pH\",\n                              variable == \"bd\" ~ \"Soil bulk density\",\n                              variable == \"log_sand_clay\" ~ \"log(Sand/Clay)\",\n                              # Variable == \"clay\" ~ \"Clay\",\n                              variable == \"log_silt_clay\" ~ \"log(Silt/Clay)\",\n                              variable == \"elevation\" ~ \"Elevation\",\n                              TRUE ~ variable)) %>% \n  mutate(variable = str_replace(variable, \"`\", \"\"),\n         variable = str_replace(variable, \"`\", \"\"),\n         variable = str_replace(variable, \"  \", \" \")) %>% \n  mutate(variable= as.factor(variable))\n\n\n\n\n#graph1\nshap_long_tidy %>% \n  ggplot(aes(mean_value,reorder(variable, mean_value), color = mean_value))+\n  geom_errorbar(aes(xmin = 0, xmax = mean_value),\n                width = 0)+\n  geom_point( size= 2)+\n  scale_color_gradient(low =\"#1e88e5ff\", high = \"#ff0d57ff\",limits =c(0,1),\n                       breaks = c(0, 1), labels = c(\" Low\", \"High \"))+\n  background_grid(major = c(\"y\"), size.major = 0.2)+\n  labs(x = \"Mean(|SHAP value|)\",\n       y =\"\",\n       color = 'Predictor value',\n       subtitle = \"Global predictor importance\")+\n  # scale_x_continuous(limits =c(0,0.5))+\n  \n  \n#graph2\nshap_long_tidy %>% \n  mutate(variable = str_replace(variable, \"`\", \"\"),\n         variable = str_replace(variable, \"`\", \"\")) %>% \n  ggplot(aes(value, reorder(variable, mean_value), color = stdfvalue))+\n  geom_vline(xintercept = 0, linetype =2) +\n  geom_jitter(height = 0.2)+\n  scale_color_gradient(low =\"#1e88e5ff\", high = \"#ff0d57ff\",limits =c(0,1),\n                       breaks = c(0, 1), labels = c(\" Low\", \"High \"))+\n  labs(x = \"SHAP value (impact on model output)\",\n       y = \"\",\n       color = 'Predictor value',\n       subtitle = \"Local explanation summary\")+\n  scale_x_continuous(breaks = seq(-3, 3,0.5 ))+\n  background_grid(major = c(\"y\"), size.major = 0.2)+\n  theme(axis.text.y = element_blank(),\n        axis.line.y = element_blank(),\n        axis.ticks.y = element_blank(),\n        plot.subtitle = element_text(hjust = 0.6))+\n  \n  #patchwork\n  \n  plot_layout(guides = \"collect\",widths = c(1,1.5) )+\n  plot_annotation(tag_levels = \"A\")\n\n\n\nggsave(\"figs/xboost_figs/SHAP_values.png\",height = 6, width = 12, dpi=600, bg = \"white\")\n\n\n\n\n\n# do.call(patchwork::wrap_plots, lapply(var_names12[1:9],influence_plot))+\nshap_vars =  as.character(unique(shap_long_tidy$variable))\n\n\ndo.call(patchwork::wrap_plots,\n        lapply(1:10, \n               function(i){\n                 shap.plot.dependence(data_long = shap_long_tidy,\n                                      x = shap_vars[i],\n                                      smooth = F,\n                                      color_feature = \"auto\")+\n                   geom_smooth(se = F,\n                               color = \"black\",\n                               method = \"gam\",\n                               formula = y ~ s(x, bs = \"cs\", k = 15))+\n                   theme_half_open(font_size = 10)+\n                   scale_color_gradient(low =\"#1e88e5ff\",\n                                        high = \"#ff0d57ff\",\n                                        n.breaks = 5,\n                                        guide = guide_colorbar(barwidth = 5,\n                                                               barheight = 0.3))+\n                   labs(title = paste(shap_vars[i]),\n                        y = paste0(\"SHAP value for\\n\", shap_vars[i]))+\n                   scale_x_continuous(n.breaks = 6)+\n                   # scale_y_continuous(limits = c(-1.5, 1.5))+\n                   theme(legend.position = \"top\",\n                         legend.text = element_text(size=5, angle = 25),\n                         legend.title = element_text(size=7))\n                 }\n               )\n)+\n  plot_layout(ncol = 2)+\n  plot_annotation(tag_levels = \"A\")\n\n\n\nggsave(\"figs/xboost_figs/shap_dependence.png\", dpi = 900, height = 11, width = 7,bg=\"white\")\n\n\ndo.call(patchwork::wrap_plots,\n        lapply(11:length(shap_vars), \n               function(i){\n                 shap.plot.dependence(data_long = shap_long_tidy,\n                                      x = shap_vars[i],\n                                      smooth = F,\n                                      color_feature = \"auto\")+\n                   geom_smooth(se = F,\n                               color = \"black\",\n                               method = \"gam\",\n                               formula = y ~ s(x, bs = \"cs\", k = 15))+\n                   theme_half_open(font_size = 10)+\n                   scale_color_gradient(low =\"#1e88e5ff\",\n                                        high = \"#ff0d57ff\",\n                                        n.breaks = 5,\n                                        guide = guide_colorbar(barwidth = 5,\n                                                               barheight = 0.3))+\n                   labs(title = paste(shap_vars[i]),\n                        y = paste0(\"SHAP value for\\n\", shap_vars[i]))+\n                   theme(legend.position = \"top\",\n                         axis.title.y = element_text(), \n                         legend.text = element_text(size=6, angle = 25),\n                         legend.title = element_text(size=7))\n                 }\n               )\n)+\n  plot_layout(ncol = 4)+\n  plot_annotation(tag_levels = \"A\")\n\n\n\nggsave(\"figs/xboost_figs/shap_dependence_remainig.png\", dpi = 600, height = 15, width = 15,bg=\"white\")"
  }
]